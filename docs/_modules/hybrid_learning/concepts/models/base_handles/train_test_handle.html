

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>hybrid_learning.concepts.models.base_handles.train_test_handle &mdash; hybrid_learning  documentation</title>
  

  
  <link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/autoclasstoc.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../../" src="../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../_static/jquery.js"></script>
        <script src="../../../../../_static/underscore.js"></script>
        <script src="../../../../../_static/doctools.js"></script>
        <script src="../../../../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../../index.html" class="icon icon-home" alt="Documentation Home"> hybrid_learning
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Content</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../quickstart/index.html">Quickstart Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../userguide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../apiref/index.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../contributing.html">How to contribute</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">hybrid_learning</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../../index.html">Module code</a> &raquo;</li>
        
      <li>hybrid_learning.concepts.models.base_handles.train_test_handle</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for hybrid_learning.concepts.models.base_handles.train_test_handle</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Abstract handle for standard training and testing of pytorch models.&quot;&quot;&quot;</span>

<span class="c1">#  Copyright (c) 2020 Continental Automotive GmbH</span>

<span class="c1"># pylint: enable=no-name-in-module</span>

<span class="kn">import</span> <span class="nn">abc</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> \
    <span class="n">List</span><span class="p">,</span> <span class="n">Sequence</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span>
<span class="kn">import</span> <span class="nn">torch.utils</span>
<span class="c1"># pylint: disable=no-name-in-module</span>
<span class="kn">from</span> <span class="nn">torch.optim.optimizer</span> <span class="kn">import</span> <span class="n">Optimizer</span>
<span class="c1"># pylint: enable=no-name-in-module</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">ConcatDataset</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Subset</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">from</span> <span class="nn">hybrid_learning.datasets</span> <span class="kn">import</span> <span class="n">BaseDataset</span><span class="p">,</span> <span class="n">DataTriple</span><span class="p">,</span> <span class="n">DatasetSplit</span>
<span class="kn">from</span> <span class="nn">hybrid_learning.datasets</span> <span class="kn">import</span> <span class="n">cross_validation_splits</span>
<span class="kn">from</span> <span class="nn">hybrid_learning.datasets.transforms</span> <span class="kn">import</span> <span class="n">ReduceTuple</span>
<span class="kn">from</span> <span class="nn">hybrid_learning.datasets.transforms</span> <span class="kn">import</span> <span class="n">TupleTransforms</span>
<span class="kn">from</span> <span class="nn">.early_stopping</span> <span class="kn">import</span> <span class="n">EarlyStoppingHandle</span>
<span class="kn">from</span> <span class="nn">.resettable_optimizer</span> <span class="kn">import</span> <span class="n">ResettableOptimizer</span>
<span class="kn">from</span> <span class="nn">...kpis</span> <span class="kn">import</span> <span class="n">BalancedBCELoss</span><span class="p">,</span> <span class="n">SetIoU</span><span class="p">,</span> <span class="n">IoU</span>

<span class="n">LOGGER</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_validate_templ</span><span class="p">(</span><span class="n">templ</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">var_names</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
    <span class="sd">&quot;&quot;&quot;Raise if the template is missing a variable name.&quot;&quot;&quot;</span>
    <span class="n">format_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;{&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">var_name</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;}&#39;</span> <span class="k">for</span> <span class="n">var_name</span> <span class="ow">in</span> <span class="n">var_names</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">([</span><span class="n">s</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">templ</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">format_vars</span><span class="p">]):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">((</span><span class="s2">&quot;string template must contain all formatting strings &quot;</span>
                          <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> but was </span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">format_vars</span><span class="p">,</span> <span class="n">templ</span><span class="p">))</span>


<div class="viewcode-block" id="TrainEvalHandle"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle">[docs]</a><span class="k">class</span> <span class="nc">TrainEvalHandle</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">ABC</span><span class="p">):</span>
    <span class="c1"># pylint: disable=line-too-long</span>
    <span class="sd">&quot;&quot;&quot;Handle for training and evaluation of pytorch models.</span>
<span class="sd">    The model base class should be :py:class:`torch.nn.Module`.</span>

<span class="sd">    The main functions are :py:meth:`train` and :py:meth:`evaluate`.</span>
<span class="sd">    Metrics and loss functions must be given on initialization.</span>
<span class="sd">    Training and evaluation results are returned as</span>
<span class="sd">    :py:class:`pandas.DataFrame` resp. :py:class:`pandas.Series` with columns</span>
<span class="sd">    the metric keys (prefixed according to the mode).</span>
<span class="sd">    Modes can be train, test, or validation (see instances of</span>
<span class="sd">    :py:class:`~hybrid_learning.datasets.base.DatasetSplit` enum).</span>
<span class="sd">    The non-prefixed loss key is saved in :py:const:`LOSS_KEY`.</span>

<span class="sd">    For a usage example see</span>
<span class="sd">    :py:class:`~hybrid_learning.concepts.models.concept_detection.ConceptDetection2DTrainTestHandle`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># pylint: enable=line-too-long</span>
    <span class="n">LOSS_KEY</span> <span class="o">=</span> <span class="s1">&#39;loss&#39;</span>
    <span class="sd">&quot;&quot;&quot;Key for the loss evaluation results.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="TrainEvalHandle.prefix_by"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.prefix_by">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">prefix_by</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">mode</span><span class="p">:</span> <span class="n">DatasetSplit</span><span class="p">,</span> <span class="n">string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Prefix ``s`` with the given mode.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">string</span><span class="p">)</span></div>

<div class="viewcode-block" id="TrainEvalHandle.test_"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.test_">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">test_</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">metric_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Get name of metric for testing results.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">prefix_by</span><span class="p">(</span><span class="n">DatasetSplit</span><span class="o">.</span><span class="n">TEST</span><span class="p">,</span> <span class="n">metric_name</span><span class="p">)</span></div>

<div class="viewcode-block" id="TrainEvalHandle.train_"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.train_">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">train_</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">metric_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Get name of metric for training results.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">prefix_by</span><span class="p">(</span><span class="n">DatasetSplit</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="n">metric_name</span><span class="p">)</span></div>

<div class="viewcode-block" id="TrainEvalHandle.val_"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.val_">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">val_</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">metric_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Get name of metric for validation results.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">prefix_by</span><span class="p">(</span><span class="n">DatasetSplit</span><span class="o">.</span><span class="n">VAL</span><span class="p">,</span> <span class="n">metric_name</span><span class="p">)</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">settings</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;The current training settings as dictionary.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">max_epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">,</span>
            <span class="n">loss_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">,</span>
            <span class="n">metric_fns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_fns</span><span class="p">,</span>
            <span class="n">early_stopping_handle</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">early_stopping_handle</span><span class="p">,</span>
            <span class="n">optimizer_creator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
        <span class="p">)</span>

<div class="viewcode-block" id="TrainEvalHandle.__init__"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
                 <span class="n">data</span><span class="p">:</span> <span class="n">DataTriple</span><span class="p">,</span>
                 <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span>
                     <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">metric_fns</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[</span>
                     <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">early_stopping_handle</span><span class="p">:</span> <span class="n">EarlyStoppingHandle</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">optimizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">Optimizer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">model_output_transform</span><span class="p">:</span> <span class="n">TupleTransforms</span> <span class="o">=</span> <span class="kc">None</span>
                 <span class="p">):</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
        <span class="c1"># pylint: disable=line-too-long</span>
        <span class="sd">&quot;&quot;&quot;Init.</span>

<span class="sd">        :param model: model to train/eval</span>
<span class="sd">        :param device: device on which to load the data and the model parameters</span>
<span class="sd">        :param optimizer: callable that yields a fresh optimizer instance</span>
<span class="sd">            when called on the model&#39;s trainable parameters</span>
<span class="sd">        :param early_stopping_handle: handle for early stopping;</span>
<span class="sd">            defaults to default</span>
<span class="sd">            :py:class:`~hybrid_learning.concepts.models.base_handles.early_stopping.EarlyStoppingHandle`</span>
<span class="sd">            if ``None``; set to ``False`` to disable early stopping;</span>
<span class="sd">        :param loss_fn: differentiable metric function to use as loss</span>
<span class="sd">        :param metric_fns: Dictionary of metric functions, each accepting</span>

<span class="sd">            - the batch model output tensor, and</span>
<span class="sd">            - the batch ground truth tensor</span>

<span class="sd">            and yields the value of the specified metric.</span>
<span class="sd">        :param model_output_transform: transformation applied to the tuples of</span>
<span class="sd">            ``(model output, target)`` before applying loss functions or</span>
<span class="sd">            metric functions;</span>
<span class="sd">            the functions are wrapped correspondingly</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># pylint: enable=line-too-long</span>

        <span class="c1"># The model to train/eval</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">model</span>
        <span class="sd">&quot;&quot;&quot;The model to work on.&quot;&quot;&quot;</span>

        <span class="c1"># General args</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="sd">&quot;&quot;&quot;Device to run training and testing on (this is where the data</span>
<span class="sd">        loaders are put).&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="ow">or</span> <span class="mi">8</span>
        <span class="sd">&quot;&quot;&quot;Default batch size.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">max_epochs</span> <span class="ow">or</span> <span class="mi">5</span>
        <span class="sd">&quot;&quot;&quot;Default maximum number of epochs.</span>
<span class="sd">        May be reduced by :py:attr:`early_stopping_handle`.&quot;&quot;&quot;</span>

        <span class="c1"># KPI functions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">loss_fn</span> <span class="k">if</span> <span class="n">loss_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">BalancedBCELoss</span><span class="p">(</span>
                <span class="n">factor_pos_class</span><span class="o">=</span><span class="mf">0.99</span><span class="p">)</span>
        <span class="sd">&quot;&quot;&quot;Loss function callable.</span>
<span class="sd">        Defaults to a balanced binary cross-entropy assuming on average 1%</span>
<span class="sd">        positive px per img.</span>
<span class="sd">        Must be wrapped into a tuple to hide the parameters, since these are</span>
<span class="sd">        not to be updated.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric_fns</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span>
            <span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> \
            <span class="n">metric_fns</span> <span class="ow">or</span> <span class="p">{</span><span class="s2">&quot;set_iou&quot;</span><span class="p">:</span> <span class="n">SetIoU</span><span class="p">(),</span> <span class="s2">&quot;mean_iou&quot;</span><span class="p">:</span> <span class="n">IoU</span><span class="p">()}</span>
        <span class="sd">&quot;&quot;&quot;Dictionary of metric functions to apply for evaluation and logging.</span>
<span class="sd">        Each function must have a signature of</span>
<span class="sd">        ``(output, target) -&gt; metric_value``.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">model_output_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">ReduceTuple</span><span class="p">(</span><span class="n">model_output_transform</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_fns</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">metric_fns</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">ReduceTuple</span><span class="p">(</span><span class="n">model_output_transform</span><span class="p">,</span>
                                                    <span class="bp">self</span><span class="o">.</span><span class="n">metric_fns</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>

        <span class="c1"># Additional handles</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">:</span> <span class="n">ResettableOptimizer</span> <span class="o">=</span> \
            <span class="n">optimizer</span> <span class="ow">or</span> <span class="n">ResettableOptimizer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
                                             <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
                                             <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.</span>
                                             <span class="c1"># do not add L2 regularization</span>
                                             <span class="p">)</span>
        <span class="sd">&quot;&quot;&quot;Optimizer and learning rate scheduler handle.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">early_stopping_handle</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EarlyStoppingHandle</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span> \
            <span class="k">if</span> <span class="n">early_stopping_handle</span> <span class="ow">is</span> <span class="kc">False</span> <span class="k">else</span> <span class="p">(</span>
                <span class="n">early_stopping_handle</span> <span class="ow">or</span> <span class="n">EarlyStoppingHandle</span><span class="p">())</span>
        <span class="sd">&quot;&quot;&quot;Handle that is stepped during training and indicates need for</span>
<span class="sd">        early stopping.</span>
<span class="sd">        To disable early stopping, set :py:attr:`early_stopping_handle` to</span>
<span class="sd">        ``None`` resp. specify ``early_stopping_handle=False`` in</span>
<span class="sd">        ``__init__`` arguments.&quot;&quot;&quot;</span>

        <span class="c1"># Data loaders</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">:</span> <span class="n">DataTriple</span> <span class="o">=</span> <span class="n">data</span>
        <span class="sd">&quot;&quot;&quot;Train, validation, and test data splits to use.</span>
<span class="sd">        Must be converted to data loaders before usage.&quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="TrainEvalHandle.loader"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.loader">[docs]</a>    <span class="k">def</span> <span class="nf">loader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">BaseDataset</span><span class="p">],</span>
               <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
               <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Prepare and return a torch data loader from the dataset</span>
<span class="sd">        according to settings.</span>
<span class="sd">        The settings include the device and batch size.</span>

<span class="sd">        :param data: data to obtain loader for</span>
<span class="sd">        :param batch_size: the batch size to apply; defaults to</span>
<span class="sd">            :py:attr:`batch_size`</span>
<span class="sd">        :param shuffle: Whether the loader should shuffle the data or not;</span>
<span class="sd">            e.g. shuffle training data and do not shuffle evaluation data</span>
<span class="sd">        :param device: the desired device to work on</span>
<span class="sd">            (determines whether to pin memory); currently unused</span>
<span class="sd">        :return: a data loader for the given data</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># It looks like pinning and threading causes issues, so skip this:</span>
        <span class="c1"># noinspection PyUnusedLocal</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">device</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
        <span class="c1"># loader_kwargs = {}</span>
        <span class="c1"># dict(num_workers=1, pin_memory=True) if device.type == &#39;cuda&#39; else {}</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
                          <span class="n">batch_size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span>
                                      <span class="k">else</span> <span class="n">batch_size</span><span class="p">))</span></div>

<div class="viewcode-block" id="TrainEvalHandle.train_loader"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.train_loader">[docs]</a>    <span class="k">def</span> <span class="nf">train_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                     <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                     <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return a loader for the train data with default settings.</span>
<span class="sd">        Train data is retrieved from the :py:attr:`data` triple.&quot;&quot;&quot;</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">device</span> <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                           <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span></div>

<div class="viewcode-block" id="TrainEvalHandle.disable_early_stopping"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.disable_early_stopping">[docs]</a>    <span class="k">def</span> <span class="nf">disable_early_stopping</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Disable early stopping.</span>
<span class="sd">        This is done by setting :py:attr:`early_stopping_handle` to ``None``.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">early_stopping_handle</span> <span class="o">=</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="TrainEvalHandle.reset_optimizer"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.reset_optimizer">[docs]</a>    <span class="k">def</span> <span class="nf">reset_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">ResettableOptimizer</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                        <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Move model to correct device, init optimizer to parameters of model.</span>
<span class="sd">        By default apply to :py:attr:`optimizer`, :py:attr:`device`,</span>
<span class="sd">        :py:attr:`model`.&quot;&quot;&quot;</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">model</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">device</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>

        <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">init</span><span class="p">([</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">optimizer</span></div>

<div class="viewcode-block" id="TrainEvalHandle.reset_training_handles"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.reset_training_handles">[docs]</a>    <span class="k">def</span> <span class="nf">reset_training_handles</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                               <span class="n">optimizer</span><span class="p">:</span> <span class="n">ResettableOptimizer</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                               <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                               <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                               <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;(Re)set all handles associated with training, and move to ``device``.</span>
<span class="sd">        These are: :py:attr:`optimizer`, :py:attr:`early_stopping_handle`,</span>
<span class="sd">        and the data loaders.</span>
<span class="sd">        The argument values default to the corresponding attributes of this</span>
<span class="sd">        instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">early_stopping_handle</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">early_stopping_handle</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span></div>

<div class="viewcode-block" id="TrainEvalHandle.train"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
              <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
              <span class="n">early_stopping_handle</span><span class="p">:</span> <span class="n">EarlyStoppingHandle</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
              <span class="n">batch_info_templ</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Epoch </span><span class="si">{epoch}</span><span class="s2">/</span><span class="si">{tot_epochs}</span><span class="se">\t</span><span class="s2">&quot;</span>
                                      <span class="s2">&quot;Batch </span><span class="si">{batch}</span><span class="s2">/</span><span class="si">{tot_batches}</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span>
              <span class="n">show_progress_bars</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
              <span class="n">pbar_desc_templ</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Epoch </span><span class="si">{epoch}</span><span class="s2">/</span><span class="si">{tot_epochs}</span><span class="s2">&quot;</span><span class="p">,</span>
              <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
              <span class="o">**</span><span class="n">custom_args</span>
              <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Train the model according to the specified training parameters.</span>
<span class="sd">        Defaults are taken from :py:attr:`settings`.</span>
<span class="sd">        To override specify ``custom_args`` (compare arguments to</span>
<span class="sd">        :py:attr:`train_val_one_epoch`).</span>

<span class="sd">        :param early_stopping_handle: handle for early stopping;</span>
<span class="sd">            set to ``False`` to disable;</span>
<span class="sd">            make sure it is reset if handle given and this is required!</span>
<span class="sd">        :param epochs: maximum number of epochs to run</span>
<span class="sd">        :param device: the device on which to run training and evaluation</span>
<span class="sd">        :param show_progress_bars: whether to verbosely show the progress using</span>
<span class="sd">            :py:class:`tqdm.tqdm` progress bar</span>
<span class="sd">        :param batch_info_templ: string template for logging epoch and batch,</span>
<span class="sd">            including as substring</span>

<span class="sd">            - ``{epoch}``: the current epoch number</span>
<span class="sd">            - ``{tot_epoch}``: total number of epochs</span>
<span class="sd">            - ``{batch}``: the current batch number</span>
<span class="sd">            - ``{tot_batches}``: total number of batches</span>

<span class="sd">        :param pbar_desc_templ: template for the progress bar description;</span>
<span class="sd">            must accept as substring</span>

<span class="sd">            - ``{epoch}``: the current epoch number</span>
<span class="sd">            - ``{tot_epoch}``: the total number of epochs</span>

<span class="sd">        :return: Two `pandas.DataFrame` with history information on</span>

<span class="sd">            - *training*: the epoch- and batch-wise loss and KPI results on the</span>
<span class="sd">              training data,</span>
<span class="sd">              index is a multi-index of ``(epoch, batch)``;</span>
<span class="sd">            - *test*: the epoch-wise evaluation results on the test set;</span>
<span class="sd">              index is the epoch index;</span>

<span class="sd">            columns for both are ``loss`` and KPI names</span>
<span class="sd">            (keys of :py:attr:`metric_fns`)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># region Default values and value checks</span>
        <span class="n">_validate_templ</span><span class="p">(</span><span class="n">batch_info_templ</span><span class="p">,</span>
                        <span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="s1">&#39;tot_epochs&#39;</span><span class="p">,</span> <span class="s1">&#39;batch&#39;</span><span class="p">,</span> <span class="s1">&#39;tot_batches&#39;</span><span class="p">))</span>
        <span class="n">_validate_templ</span><span class="p">(</span><span class="n">pbar_desc_templ</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="s1">&#39;tot_epochs&#39;</span><span class="p">))</span>

        <span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span>
        <span class="c1"># Push model to correct device and reset training handles</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">custom_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_training_handles</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                                    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
                                    <span class="n">model</span><span class="o">=</span><span class="n">custom_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">early_stopping_handle</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">early_stopping_handle</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">early_stopping_handle</span>
        <span class="c1"># endregion</span>

        <span class="n">history_train</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">history_val</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
            <span class="c1"># Train and evaluate (with nice progress bar if requested)</span>
            <span class="n">kpis_train</span><span class="p">,</span> <span class="n">kpis_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_val_one_epoch</span><span class="p">(</span>
                <span class="o">**</span><span class="n">custom_args</span><span class="p">,</span>
                <span class="n">show_progress_bar</span><span class="o">=</span><span class="n">show_progress_bars</span><span class="p">,</span>
                <span class="n">pbar_desc</span><span class="o">=</span><span class="n">pbar_desc_templ</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                                                 <span class="n">tot_epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">),</span>
                <span class="n">batch_info_templ</span><span class="o">=</span><span class="n">batch_info_templ</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tot_epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
                    <span class="n">batch</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">{batch}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">tot_batches</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">{tot_batches}</span><span class="s1">&#39;</span><span class="p">))</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">epoch_end</span><span class="p">()</span>

            <span class="n">history_train</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">kpis_train</span>
            <span class="n">history_val</span><span class="p">[</span><span class="n">epoch</span><span class="p">]</span> <span class="o">=</span> <span class="n">kpis_val</span>
            <span class="c1"># Stop early if necessary</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">early_stopping_handle</span> <span class="ow">and</span>
                    <span class="n">early_stopping_handle</span><span class="o">.</span><span class="n">step</span><span class="p">(</span>
                        <span class="n">kpis_val</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">val_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">LOSS_KEY</span><span class="p">)])):</span>
                <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Stopped early after </span><span class="si">%d</span><span class="s2"> epochs.&quot;</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                <span class="k">break</span>
        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">history_train</span><span class="p">),</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history_val</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span></div>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_log_range</span><span class="p">(</span><span class="n">min_val</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">max_val</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>  <span class="c1"># TODO: test</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Iterate in :math:`\times 10` steps from ``min_val`` to ``max_val``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">max_val</span> <span class="o">&lt;</span> <span class="n">min_val</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;max (</span><span class="si">{}</span><span class="s2">) was smaller than min (</span><span class="si">{}</span><span class="s2">).&quot;</span>
                             <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">max_val</span><span class="p">,</span> <span class="n">min_val</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">min_val</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only min &gt;0 allowed, but min was </span><span class="si">{}</span><span class="s2">&quot;</span>
                             <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">min_val</span><span class="p">))</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">min_val</span> <span class="o">*</span> <span class="p">(</span><span class="mi">10</span> <span class="o">**</span> <span class="n">a</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span>
                <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">max_val</span> <span class="o">/</span> <span class="n">min_val</span><span class="p">)))]</span>

<div class="viewcode-block" id="TrainEvalHandle.cross_validate"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.cross_validate">[docs]</a>    <span class="k">def</span> <span class="nf">cross_validate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_splits</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                       <span class="n">train_val_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                       <span class="n">run_info_templ</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;Run </span><span class="si">{run}</span><span class="s1">/</span><span class="si">{runs}</span><span class="s1">&#39;</span><span class="p">,</span>
                       <span class="o">**</span><span class="n">custom_args</span>
                       <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
                                       <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
                                       <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;Record training results for ``num_splits`` distinct val splits.</span>
<span class="sd">        The original model state dict is restored after training runs.</span>
<span class="sd">        The model must feature a ``reset_parameters()`` method to reinitialize</span>
<span class="sd">        between the runs.</span>

<span class="sd">        :param run_info_templ: template containing as substring placeholders</span>
<span class="sd">            ``{run}`` (the number of the current run) and ``runs``</span>
<span class="sd">            (the total number of runs);</span>
<span class="sd">            the template is prefixed to ``batch_info_templ`` and</span>
<span class="sd">            ``pbar_desc_templ``</span>
<span class="sd">        :param batch_size: optional ``batch_size`` to use for the loaders;</span>
<span class="sd">            defaults to :py:attr:`batch_size`</span>
<span class="sd">        :param num_splits: number of equal-sized, distinct validation splits</span>
<span class="sd">            to use</span>
<span class="sd">        :param train_val_data: optional given dataset to split into train and</span>
<span class="sd">            validation dataset splits; defaults to the ``train_val`` split in</span>
<span class="sd">            :py:attr:`data`</span>
<span class="sd">        :param custom_args: further custom training args overriding defaults</span>
<span class="sd">        :return: list of tuples of the form</span>

<span class="sd">            | (</span>
<span class="sd">            |     final ``state_dict``,</span>
<span class="sd">            |     epoch- and batch-wise train history as</span>
<span class="sd">                  :py:class:`pandas.DataFrame`,</span>
<span class="sd">            |     epoch-wise validation history as :py:class:`pandas.DataFrame`</span>
<span class="sd">            | )</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">{run}</span><span class="s2">&quot;</span> <span class="ow">in</span> <span class="n">run_info_templ</span> <span class="ow">and</span> <span class="s2">&quot;</span><span class="si">{runs}</span><span class="s2">&quot;</span> <span class="ow">in</span> <span class="n">run_info_templ</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;run_info_templ must contain formatting strings &quot;</span>
                             <span class="s2">&quot;</span><span class="si">{run}</span><span class="s2"> and </span><span class="si">{runs}</span><span class="s2"> but was &quot;</span> <span class="o">+</span> <span class="n">run_info_templ</span><span class="p">)</span>
        <span class="c1"># region Default values</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">custom_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="n">train_val_data</span> <span class="o">=</span> <span class="n">train_val_data</span> <span class="k">if</span> <span class="n">train_val_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> \
            <span class="n">ConcatDataset</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">val</span><span class="p">])</span>

        <span class="k">def</span> <span class="nf">logging_settings</span><span class="p">(</span><span class="n">curr_run</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
            <span class="sd">&quot;&quot;&quot;Return logging template settings for given lr and run.</span>
<span class="sd">            Helper function.&quot;&quot;&quot;</span>
            <span class="n">epoch_info</span> <span class="o">=</span> <span class="s2">&quot;, epoch </span><span class="si">{epoch}</span><span class="s2">/</span><span class="si">{tot_epochs}</span><span class="s2">&quot;</span>
            <span class="n">run_info</span> <span class="o">=</span> <span class="n">run_info_templ</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">run</span><span class="o">=</span><span class="n">curr_run</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">runs</span><span class="o">=</span><span class="n">num_splits</span><span class="p">)</span>
            <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span>
                <span class="n">pbar_desc_templ</span><span class="o">=</span><span class="n">run_info</span> <span class="o">+</span> <span class="n">custom_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s1">&#39;pbar_desc_templ&#39;</span><span class="p">,</span> <span class="n">epoch_info</span><span class="p">),</span>
                <span class="n">batch_info_templ</span><span class="o">=</span><span class="n">run_info</span> <span class="o">+</span> <span class="n">custom_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="s1">&#39;batch_info_templ&#39;</span><span class="p">,</span>
                    <span class="n">epoch_info</span> <span class="o">+</span> <span class="s2">&quot;, batch </span><span class="si">{batch}</span><span class="s2">/</span><span class="si">{tot_batches}</span><span class="s2">&quot;</span><span class="p">))</span>

        <span class="c1"># end region</span>

        <span class="c1"># Save original model parameters:</span>
        <span class="n">orig_state_dict</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>

        <span class="n">splits</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Subset</span><span class="p">,</span> <span class="n">Subset</span><span class="p">]]</span> <span class="o">=</span> \
            <span class="n">cross_validation_splits</span><span class="p">(</span><span class="n">train_val_data</span><span class="p">,</span> <span class="n">num_splits</span><span class="o">=</span><span class="n">num_splits</span><span class="p">)</span>
        <span class="n">results</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
                            <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
                            <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">run</span><span class="p">,</span> <span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">splits</span><span class="p">):</span>
            <span class="n">model</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>
            <span class="n">history_train</span><span class="p">,</span> <span class="n">history_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
                <span class="c1"># Use the created train val split</span>
                <span class="n">train_loader</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loader</span><span class="p">(</span>
                    <span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">custom_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;device&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)),</span>
                <span class="n">val_loader</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loader</span><span class="p">(</span>
                    <span class="n">val_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">custom_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;device&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)),</span>
                <span class="c1"># Use the amended log infos</span>
                <span class="o">**</span><span class="p">{</span><span class="o">**</span><span class="n">custom_args</span><span class="p">,</span> <span class="o">**</span><span class="n">logging_settings</span><span class="p">(</span><span class="n">run</span><span class="p">),</span> <span class="s1">&#39;model&#39;</span><span class="p">:</span> <span class="n">model</span><span class="p">}</span>
            <span class="p">)</span>
            <span class="c1"># collect the state dict</span>
            <span class="n">curr_state_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
            <span class="c1"># properly copy it and move to CPU to not overload GPU:</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">curr_state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">curr_state_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> \
                    <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span>
                        <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
            <span class="c1"># save results:</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">curr_state_dict</span><span class="p">,</span> <span class="n">history_train</span><span class="p">,</span> <span class="n">history_val</span><span class="p">))</span>

        <span class="c1"># Restore original model parameters:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">orig_state_dict</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results</span></div>

<div class="viewcode-block" id="TrainEvalHandle.assess_learning_rates"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.assess_learning_rates">[docs]</a>    <span class="k">def</span> <span class="nf">assess_learning_rates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                              <span class="n">min_lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">,</span>
                              <span class="n">max_lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                              <span class="n">lr_candidates</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                              <span class="n">runs_per_lr</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                              <span class="o">**</span><span class="n">train_args</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Collect mean and std deviation of loss for lr candidates via</span>
<span class="sd">        cross-validation.</span>
<span class="sd">        If no ``lr_candidates`` are given, candidates are chosen in a</span>
<span class="sd">        logarithmic range from ``min_lr`` to ``max_lr``, i.e.</span>
<span class="sd">        ``min_lr * (10**a)`` for ``a=0`` to ``int(log10(max_lr / min_lr))``.</span>

<span class="sd">        :param lr_candidates: learning rate candidate values to collect</span>
<span class="sd">            performance values for</span>
<span class="sd">        :param min_lr: minimum learning rate to automatically determine</span>
<span class="sd">            candidates; overridden by ``lr_candidates``</span>
<span class="sd">        :param max_lr: maximum learning rate to automatically determine</span>
<span class="sd">            candidates; overridden by ``lr_candidates``</span>
<span class="sd">        :param runs_per_lr: number of cross-validation splits to make for each</span>
<span class="sd">            learning rate candidate</span>
<span class="sd">        :param train_args: further arguments to override instance defaults for</span>
<span class="sd">            the training runs, like ``epochs``, ``early_stopping_handle``</span>
<span class="sd">            etc. (see :py:meth:`train`);</span>
<span class="sd">            must not encompass ``train_loader`` or ``val_loader``</span>
<span class="sd">            (specify ``train_val_data`` instead)</span>
<span class="sd">        :return: :py:class:`pandas.DataFrame` indexed by the learning rate</span>
<span class="sd">            candidates with columns for mean and standard deviation of the</span>
<span class="sd">            last epoch&#39;s validation loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># region Defaults and value checks</span>
        <span class="k">if</span> <span class="n">runs_per_lr</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;runs_per_lr must be &gt;0, but was </span><span class="si">{}</span><span class="s2">&quot;</span>
                             <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">runs_per_lr</span><span class="p">))</span>
        <span class="n">lr_candidates</span> <span class="o">=</span> <span class="n">lr_candidates</span> <span class="k">if</span> <span class="n">lr_candidates</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_range</span><span class="p">(</span><span class="n">min_lr</span><span class="p">,</span> <span class="n">max_lr</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">l_rate</span> <span class="ow">in</span> <span class="p">(</span><span class="n">lr</span> <span class="k">for</span> <span class="n">lr</span> <span class="ow">in</span> <span class="n">lr_candidates</span> <span class="k">if</span> <span class="n">lr</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Learning rate candidates must be &gt;0, but got </span><span class="si">{}</span><span class="s2">&quot;</span>
                             <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">l_rate</span><span class="p">))</span>
        <span class="c1"># We are only interested interested in the loss results by default:</span>
        <span class="n">train_args</span><span class="p">[</span><span class="s1">&#39;metric_fns&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;metric_fns&#39;</span><span class="p">,</span> <span class="p">{})</span>
        <span class="c1"># The optimizer is replaced by one with the same settings</span>
        <span class="c1"># but controlled learning rate:</span>
        <span class="n">optim</span><span class="p">:</span> <span class="n">ResettableOptimizer</span> <span class="o">=</span> <span class="n">train_args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>
        <span class="n">optim_args</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">optim</span><span class="o">.</span><span class="n">settings</span><span class="p">,</span>
                      <span class="o">**</span><span class="nb">dict</span><span class="p">(</span><span class="n">lr_scheduler_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_update_lr</span><span class="o">=</span><span class="kc">False</span><span class="p">)}</span>
        <span class="c1"># endregion</span>

        <span class="c1"># Collect cross-validation results for each learning rate</span>
        <span class="n">lr_results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">l_rate</span> <span class="ow">in</span> <span class="n">lr_candidates</span><span class="p">:</span>
            <span class="n">cv_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_validate</span><span class="p">(</span>
                <span class="c1"># Here is the magic: provide optimizer w/ fixed learning rate.</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reset_optimizer</span><span class="p">(</span>
                    <span class="n">ResettableOptimizer</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="o">**</span><span class="n">optim_args</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="n">l_rate</span><span class="p">})),</span>
                <span class="n">run_info_templ</span><span class="o">=</span><span class="s2">&quot;LR </span><span class="si">{: &lt;.2e}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">l_rate</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;, run </span><span class="si">{run}</span><span class="s2">/</span><span class="si">{runs}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="o">**</span><span class="n">train_args</span>
            <span class="p">)</span>
            <span class="c1"># Select validation results from last epoch:</span>
            <span class="n">lr_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="p">[</span><span class="n">hist_val</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">hist_val</span> <span class="ow">in</span> <span class="n">cv_results</span><span class="p">]))</span>

        <span class="c1"># Collect the mean and standard deviation of the loss results</span>
        <span class="n">loss_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">LOSS_KEY</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
            <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="n">lr_candidates</span><span class="p">,</span>
            <span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="n">loss_key</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">lr_results</span><span class="p">],</span>
            <span class="s1">&#39;std.dev&#39;</span><span class="p">:</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="n">loss_key</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">lr_results</span><span class="p">]</span>
        <span class="p">})</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span></div>

    <span class="c1"># def cyclic_lr_upper_bound(self):</span>
    <span class="c1">#     &quot;&quot;&quot;Conduct a cross-validation to find the upper bound for a cyclic</span>
    <span class="c1">#     learning rate.</span>
    <span class="c1">#     https://towardsdatascience.com/2bf904d18dee</span>
    <span class="c1">#     &quot;&quot;&quot;</span>
    <span class="c1">#     # TODO: algorithm to find bounds for cyclic learning rate</span>
    <span class="c1">#     raise NotImplementedError()</span>

<div class="viewcode-block" id="TrainEvalHandle.train_val_one_epoch"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.train_val_one_epoch">[docs]</a>    <span class="k">def</span> <span class="nf">train_val_one_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                            <span class="n">show_progress_bar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                            <span class="n">pbar_desc</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Epoch ??/??&quot;</span><span class="p">,</span>
                            <span class="n">batch_info_templ</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Epoch ??/??</span><span class="se">\t</span><span class="s2">Batch &quot;</span>
                                                    <span class="s2">&quot;</span><span class="si">{batch}</span><span class="s2">/</span><span class="si">{tot_batches}</span><span class="s2">&quot;</span><span class="p">,</span>
                            <span class="o">**</span><span class="n">custom_args</span>
                            <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Train for one epoch, evaluate, and return history and test results.</span>
<span class="sd">        This is a wrapper around :py:meth:`train_one_epoch` and</span>
<span class="sd">        :py:meth:`evaluate` with nice progress bar printing and logging after</span>
<span class="sd">        the epoch.</span>
<span class="sd">        History and test results are stored in a :py:class:`pandas.DataFrame`.</span>
<span class="sd">        The device used for training is that of the parameters of the used</span>
<span class="sd">        model (see :py:meth:`device_of`).</span>

<span class="sd">        :param show_progress_bar: whether to log the batch progress, training</span>
<span class="sd">            latest loss and metrics using :py:class:`tqdm.tqdm`</span>
<span class="sd">        :param batch_info_templ: formatting template for logging that</span>
<span class="sd">            contains as substring ``{batch}`` and ``{tot_batches}``</span>
<span class="sd">        :param pbar_desc: leading static description text for the progress bar</span>
<span class="sd">        :return: tuple of training history and test results; columns resp.</span>
<span class="sd">            index are ``loss`` and the KPI names</span>
<span class="sd">            (keys from dict :py:attr:`metric_fns`).</span>

<span class="sd">            - :py:class:`pandas.DataFrame`: index are the batch indices,</span>
<span class="sd">              items are the results of KPI evaluations of the output on the</span>
<span class="sd">              training batch (i.e. before back-propagation step)</span>
<span class="sd">            - :py:class:`pandas.Series`: the items are the final evaluations of</span>
<span class="sd">              the KPIs on the validation set</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Progress bar preparations</span>
        <span class="c1"># set the default train_loader</span>
        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">custom_args</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span>
            <span class="s1">&#39;train_loader&#39;</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">(</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">custom_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_of</span><span class="p">(</span><span class="n">custom_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)))</span>
        <span class="p">)</span>
        <span class="n">pbar</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">show_progress_bar</span> <span class="k">else</span> \
            <span class="n">tqdm</span><span class="p">(</span><span class="n">desc</span><span class="o">=</span><span class="n">pbar_desc</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>

        <span class="c1"># Training</span>
        <span class="n">train_kpi_vals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_one_epoch</span><span class="p">(</span>
            <span class="n">show_progress_bar</span><span class="o">=</span><span class="n">show_progress_bar</span><span class="p">,</span> <span class="n">pbar</span><span class="o">=</span><span class="n">pbar</span><span class="p">,</span>
            <span class="n">batch_info_templ</span><span class="o">=</span><span class="n">batch_info_templ</span><span class="p">,</span>
            <span class="o">**</span><span class="n">custom_args</span>
        <span class="p">)</span>

        <span class="c1"># Evaluation</span>
        <span class="n">val_kpi_vals</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">DatasetSplit</span><span class="o">.</span><span class="n">VAL</span><span class="p">,</span> <span class="o">**</span><span class="n">custom_args</span><span class="p">))</span>

        <span class="c1"># Logging</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_log_after_epoch</span><span class="p">(</span><span class="n">train_kpi_vals</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">val_kpi_vals</span><span class="p">,</span> <span class="n">pbar</span><span class="o">=</span><span class="n">pbar</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">show_progress_bar</span><span class="p">:</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">train_kpi_vals</span><span class="p">,</span> <span class="n">val_kpi_vals</span></div>

<div class="viewcode-block" id="TrainEvalHandle.train_one_epoch"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.train_one_epoch">[docs]</a>    <span class="k">def</span> <span class="nf">train_one_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                        <span class="n">show_progress_bar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                        <span class="n">pbar</span><span class="p">:</span> <span class="n">tqdm</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                        <span class="n">pbar_desc</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Epoch ??/??&quot;</span><span class="p">,</span>
                        <span class="n">batch_info_templ</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Epoch ??/??</span><span class="se">\t</span><span class="s2">&quot;</span>
                                                <span class="s2">&quot;Batch </span><span class="si">{batch}</span><span class="s2">/</span><span class="si">{tot_batches}</span><span class="s2">&quot;</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                        <span class="o">**</span><span class="n">custom_args</span>
                        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Train for one epoch and return history results as</span>
<span class="sd">        :py:class:`pandas.DataFrame`.</span>
<span class="sd">        This is a wrapper around :py:meth:`_train_one_epoch` that uses</span>
<span class="sd">        defaults from :py:attr:`settings`.</span>
<span class="sd">        Override the defaults by specifying ``custom_args`` (but watch out</span>
<span class="sd">        that model and optimizer fit together, if any of them is overridden!).</span>

<span class="sd">        :param pbar: optional progress bar; hand over if more control over</span>
<span class="sd">            the progress bar is required</span>
<span class="sd">        :param show_progress_bar: whether to log the batch progress,</span>
<span class="sd">            training latest loss and metrics using :py:class:`tqdm.tqdm`</span>
<span class="sd">        :param batch_info_templ: formatting template for logging that contains</span>
<span class="sd">            as substring ``{batch}`` and ``{tot_batches}``</span>
<span class="sd">        :param pbar_desc: leading static description text for the progress bar</span>
<span class="sd">            if newly created</span>
<span class="sd">        :param batch_size: batch size for the ``train_loader`` if this is not</span>
<span class="sd">            given in ``custom_args``</span>
<span class="sd">        :return: tuple of training history and test results as</span>
<span class="sd">            :py:class:`pandas.DataFrame` with:</span>

<span class="sd">            :columns:</span>
<span class="sd">                ``loss`` and the KPI names</span>
<span class="sd">                (keys from dict :py:attr:`metric_fns`),</span>
<span class="sd">            :index: the batch indices,</span>
<span class="sd">            :items:</span>
<span class="sd">                the results of KPI evaluations of the output on the training</span>
<span class="sd">                batch (i.e. *before* back-propagation step)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">custom_args</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="n">train_args</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="nb">dict</span><span class="p">(</span><span class="n">loss_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">,</span>
                             <span class="n">metric_fns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_fns</span><span class="p">,</span>
                             <span class="n">train_loader</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">(</span>
                                 <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                                 <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_of</span><span class="p">(</span><span class="n">model</span><span class="p">)),</span>
                             <span class="n">optimizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
                             <span class="n">pbar</span><span class="o">=</span><span class="n">pbar</span><span class="p">,</span>
                             <span class="n">batch_info_templ</span><span class="o">=</span><span class="n">batch_info_templ</span><span class="p">),</span>
                      <span class="o">**</span><span class="n">custom_args</span><span class="p">}</span>
        <span class="c1"># Progress bar handling</span>
        <span class="k">if</span> <span class="n">show_progress_bar</span> <span class="ow">and</span> <span class="n">pbar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">train_args</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">pbar</span><span class="o">=</span><span class="n">tqdm</span><span class="p">(</span><span class="n">desc</span><span class="o">=</span><span class="n">pbar_desc</span><span class="p">,</span>
                                        <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_args</span><span class="p">[</span><span class="s1">&#39;train_loader&#39;</span><span class="p">])))</span>
        <span class="c1"># Actual training</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_one_epoch</span><span class="p">(</span><span class="o">**</span><span class="n">train_args</span><span class="p">)</span></div>

<div class="viewcode-block" id="TrainEvalHandle._train_one_epoch"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle._train_one_epoch">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_train_one_epoch</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span>
                         <span class="n">model</span><span class="p">,</span>
                         <span class="n">loss_fn</span><span class="p">,</span>
                         <span class="n">metric_fns</span><span class="p">,</span>
                         <span class="n">train_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
                         <span class="n">optimizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">ResettableOptimizer</span><span class="p">],</span>
                         <span class="n">pbar</span><span class="p">:</span> <span class="n">tqdm</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                         <span class="n">batch_info_templ</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Epoch ??/??</span><span class="se">\t</span><span class="s2">&quot;</span>
                                                 <span class="s2">&quot;Batch </span><span class="si">{batch}</span><span class="s2">/</span><span class="si">{tot_batches}</span><span class="s2">&quot;</span><span class="p">,</span>
                         <span class="o">**</span><span class="n">_unused_args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Train for one epoch, evaluate, and return history and test results.</span>
<span class="sd">        History and test results are stored in a :py:class:`pandas.DataFrame`.</span>
<span class="sd">        The device used is the one the model lies on. Distributed models are</span>
<span class="sd">        not supported.</span>

<span class="sd">        :meta public:</span>
<span class="sd">        :param model: model to train</span>
<span class="sd">        :param loss_fn: function that calculates the optimization objective</span>
<span class="sd">            value</span>
<span class="sd">        :param metric_fns: further KPI functions to gather training stats</span>
<span class="sd">        :param train_loader: train data loader</span>
<span class="sd">        :param optimizer: optimizer to use for weight update steps</span>
<span class="sd">            initialized with model&#39;s weights</span>
<span class="sd">        :param pbar: optional :py:class:`tqdm.tqdm` progress bar which is</span>
<span class="sd">            updated after each batch</span>
<span class="sd">        :param batch_info_templ: formatting template for logging</span>
<span class="sd">            that contains as substring ``{batch}`` and ``{tot_batches}``</span>
<span class="sd">        :return: training history as :py:class:`pandas.DataFrame` with</span>

<span class="sd">            :columns:</span>
<span class="sd">                ``loss`` and the KPI names</span>
<span class="sd">                (keys from dict :py:attr:`metric_fns`),</span>
<span class="sd">            :index: the batch indices,</span>
<span class="sd">            :items:</span>
<span class="sd">                the results of KPI evaluations of the output on the training</span>
<span class="sd">                batch (i.e. *before* back-propagation step)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Empty training loader (no batches)! &quot;</span>
                             <span class="s2">&quot;Batch size too large?&quot;</span><span class="p">)</span>
        <span class="c1"># very simple way to find out the correct device for</span>
        <span class="c1"># non-distributed models:</span>
        <span class="n">device</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">device_of</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="c1"># Training</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">train_kpi_vals</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
            <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="bp">cls</span><span class="o">.</span><span class="n">train_</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span>
                     <span class="p">[</span><span class="bp">cls</span><span class="o">.</span><span class="n">LOSS_KEY</span><span class="p">,</span> <span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="n">metric_fns</span><span class="o">.</span><span class="n">keys</span><span class="p">())]])</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
            <span class="n">data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Reset optimizer gradients</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># Calculate loss tensor &amp; metric(s) values</span>
            <span class="n">output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">loss_tensor</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            <span class="n">train_kpi_vals</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                <span class="bp">cls</span><span class="o">.</span><span class="n">train_</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">LOSS_KEY</span><span class="p">):</span> <span class="n">loss_tensor</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                <span class="o">**</span><span class="p">{</span><span class="bp">cls</span><span class="o">.</span><span class="n">train_</span><span class="p">(</span><span class="n">m</span><span class="p">):</span> <span class="n">fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                   <span class="k">for</span> <span class="n">m</span><span class="p">,</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">metric_fns</span><span class="o">.</span><span class="n">items</span><span class="p">()}}</span>

            <span class="c1"># Do back-propagation and apply to weight</span>
            <span class="n">loss_tensor</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># Logging</span>
            <span class="bp">cls</span><span class="o">.</span><span class="n">_log_after_batch</span><span class="p">(</span>
                <span class="n">train_kpi_vals</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">],</span> <span class="n">pbar</span><span class="o">=</span><span class="n">pbar</span><span class="p">,</span>
                <span class="n">batch_info</span><span class="o">=</span><span class="n">batch_info_templ</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                                                   <span class="n">tot_batches</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
                                                   <span class="p">))</span>

        <span class="k">return</span> <span class="n">train_kpi_vals</span></div>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_log_after_batch</span><span class="p">(</span><span class="n">batch_kpi_vals</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">batch_info</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                         <span class="n">pbar</span><span class="p">:</span> <span class="n">tqdm</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Logging of training KPI values after one batch.</span>
<span class="sd">        Optionally also append information to a progress bar.</span>

<span class="sd">        :param batch_info: information about batch and epoch to prefix to the</span>
<span class="sd">            KPI information</span>
<span class="sd">        :param batch_kpi_vals: :py:class:`pandas.Series` indexed by the</span>
<span class="sd">            KPI names for training with the KPI values over the last training</span>
<span class="sd">            batch</span>
<span class="sd">        :param pbar: progressbar to update the postfix of if given</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># log message content</span>
        <span class="n">message</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\r</span><span class="s1"> </span><span class="si">{batch_info}</span><span class="se">\t</span><span class="si">{kpi_info}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">batch_info</span><span class="o">=</span><span class="n">batch_info</span><span class="p">,</span>
            <span class="n">kpi_info</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">: </span><span class="si">{:.6f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
                                <span class="k">for</span> <span class="n">m</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch_kpi_vals</span><span class="o">.</span><span class="n">items</span><span class="p">()]))</span>
        <span class="c1"># actual logging</span>
        <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

        <span class="c1"># progress bar update</span>
        <span class="k">if</span> <span class="n">pbar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="o">**</span><span class="n">batch_kpi_vals</span><span class="p">)</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_log_after_epoch</span><span class="p">(</span><span class="n">train_kpi_vals</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">val_kpi_vals</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
                         <span class="n">pbar</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tqdm</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Logging of mean training and validation KPI values after one epoch.</span>
<span class="sd">        Optionally also append information to a progress bar.</span>

<span class="sd">        :param train_kpi_vals: :py:class:`pandas.Series` indexed by the KPI</span>
<span class="sd">            names for training with the mean KPI values over the last</span>
<span class="sd">            training epoch</span>
<span class="sd">        :param val_kpi_vals: :py:class:`pandas.Series` indexed by the KPI</span>
<span class="sd">            names for testing with the KPI values over the validation set</span>
<span class="sd">            after the epoch</span>
<span class="sd">        :param pbar: progressbar to update the postfix of if given</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Logging of evaluation results</span>
        <span class="c1"># normal logging</span>
        <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Mean train results: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s2">&quot;     </span><span class="si">{}</span><span class="s2">=</span><span class="si">{:.6f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span>
                               <span class="n">train_kpi_vals</span><span class="o">.</span><span class="n">items</span><span class="p">()]))</span>
        <span class="n">LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Test eval results:  </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">=</span><span class="si">{:.6f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span>
                               <span class="n">val_kpi_vals</span><span class="o">.</span><span class="n">items</span><span class="p">()]))</span>
        <span class="c1"># progress bar logging</span>
        <span class="k">if</span> <span class="n">pbar</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span>
                <span class="o">**</span><span class="p">{</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">m</span><span class="p">):</span> <span class="n">v</span> <span class="k">for</span> <span class="n">m</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span>
                   <span class="p">[</span><span class="o">*</span><span class="n">train_kpi_vals</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="o">*</span><span class="n">val_kpi_vals</span><span class="o">.</span><span class="n">items</span><span class="p">()]})</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">refresh</span><span class="p">()</span>

<div class="viewcode-block" id="TrainEvalHandle.evaluate"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.evaluate">[docs]</a>    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">mode</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">DatasetSplit</span><span class="p">]</span> <span class="o">=</span> <span class="n">DatasetSplit</span><span class="o">.</span><span class="n">TEST</span><span class="p">,</span>
                 <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">custom_args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Evaluate the model wrt. :py:attr:`settings`.</span>
<span class="sd">        This is a wrapper around :py:meth:`_evaluate` which uses the defaults</span>
<span class="sd">        given by :py:attr:`settings`.</span>
<span class="sd">        Override them by specifying them as ``custom_args``.</span>
<span class="sd">        The device used for evaluation is the one of the model determined using</span>
<span class="sd">        :py:meth:`device_of`.</span>

<span class="sd">        :param mode: which data set to use; specify as instance of</span>
<span class="sd">            :py:class:`~hybrid_learning.datasets.base.DatasetSplit`</span>
<span class="sd">            or the name of one</span>
<span class="sd">        :param batch_size: batch size used for the ``val_loader`` if that is</span>
<span class="sd">            not given within ``custom_args``</span>
<span class="sd">        :return: Dictionary of all KPIs, i.e. of ``loss`` and each metric</span>
<span class="sd">            in :py:attr:`metric_fns`;</span>
<span class="sd">            format: ``{&lt;KPI-name&gt;: &lt;KPI value as float&gt;}``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># region Value check</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="ow">in</span> <span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">DatasetSplit</span><span class="p">]:</span>
            <span class="n">mode</span> <span class="o">=</span> <span class="n">DatasetSplit</span><span class="p">[</span><span class="n">mode</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">DatasetSplit</span><span class="o">.</span><span class="n">VAL</span><span class="p">,</span> <span class="n">DatasetSplit</span><span class="o">.</span><span class="n">TEST</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid mode </span><span class="si">{}</span><span class="s2">; accepting one of </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">mode</span><span class="p">,</span> <span class="p">(</span><span class="n">DatasetSplit</span><span class="o">.</span><span class="n">VAL</span><span class="p">,</span> <span class="n">DatasetSplit</span><span class="o">.</span><span class="n">TEST</span><span class="p">,</span>
                       <span class="n">DatasetSplit</span><span class="o">.</span><span class="n">VAL</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">DatasetSplit</span><span class="o">.</span><span class="n">TEST</span><span class="o">.</span><span class="n">value</span><span class="p">)))</span>
        <span class="c1"># endregion</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">custom_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="n">default_eval_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">kpi_fns</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">LOSS_KEY</span><span class="p">:</span> <span class="n">custom_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;loss_fn&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">),</span>
                     <span class="o">**</span><span class="n">custom_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;metric_fns&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_fns</span><span class="p">)},</span>
            <span class="n">prefix_</span><span class="o">=</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">prefix_by</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">s</span><span class="p">)),</span>
            <span class="n">val_loader</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loader</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">test</span> <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">DatasetSplit</span><span class="o">.</span><span class="n">TEST</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">val</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_of</span><span class="p">(</span><span class="n">model</span><span class="p">)))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluate</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="o">**</span><span class="n">default_eval_args</span><span class="p">,</span> <span class="o">**</span><span class="n">custom_args</span><span class="p">})</span></div>

<div class="viewcode-block" id="TrainEvalHandle._evaluate"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle._evaluate">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_evaluate</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span>
                  <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
                  <span class="n">kpi_fns</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">],</span>
                  <span class="n">val_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
                  <span class="n">prefix_</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                  <span class="o">**</span><span class="n">_unused_args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Evaluate the model wrt. loss and :py:attr:`metric_fns`</span>
<span class="sd">        on the test data.</span>
<span class="sd">        The reduction method for the KPI values is ``mean``.</span>
<span class="sd">        The device used is the one of the model lies on (see</span>
<span class="sd">        :py:meth:`device_of`). Distributed models are not supported.</span>

<span class="sd">        :meta public:</span>
<span class="sd">        :param model: the model to evaluate</span>
<span class="sd">        :param kpi_fns: dictionary with KPI IDs and evaluation functions for</span>
<span class="sd">            the KPIs to evaluate</span>
<span class="sd">        :param val_loader: data loader with data to evaluate on</span>
<span class="sd">        :param prefix_: wrapper to prefix KPI names for the final</span>
<span class="sd">            :py:class:`pandas.Series` naming</span>
<span class="sd">        :return: Dictionary of all KPI values in the format:</span>
<span class="sd">            ``{&lt;KPI-name&gt;: &lt;KPI value as float&gt;}``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># very simple way to find out the correct device for</span>
        <span class="c1"># non-distributed models:</span>
        <span class="n">prefix_</span> <span class="o">=</span> <span class="n">prefix_</span> <span class="k">if</span> <span class="n">prefix_</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">cls</span><span class="o">.</span><span class="n">val_</span>
        <span class="n">device</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">device_of</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="c1"># Value check and defaults</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Empty evaluation data loader (no batches)! &quot;</span>
                             <span class="s2">&quot;Batch size too large?&quot;</span><span class="p">)</span>

        <span class="c1"># Combine loss and metrics as general KPI measures</span>
        <span class="n">eval_kpi_vals</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="n">prefix_</span><span class="p">(</span><span class="n">m</span><span class="p">):</span> <span class="mf">0.</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span>
                                           <span class="n">kpi_fns</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>

        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># Gather KPI values from all batches</span>
            <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
                <span class="n">data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                <span class="c1"># Add metric from batch</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">kpi</span> <span class="ow">in</span> <span class="n">kpi_fns</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">eval_kpi_vals</span><span class="p">[</span><span class="n">prefix_</span><span class="p">(</span><span class="n">kpi</span><span class="p">)]</span> <span class="o">+=</span> <span class="n">kpi_fns</span><span class="p">[</span><span class="n">kpi</span><span class="p">](</span><span class="n">output</span><span class="p">,</span>
                                                                <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

            <span class="c1"># Aggregate KPI values of all batches via mean</span>
            <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">eval_kpi</span> <span class="ow">in</span> <span class="n">eval_kpi_vals</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">eval_kpi_vals</span><span class="p">[</span><span class="n">eval_kpi</span><span class="p">]</span> <span class="o">/=</span> <span class="n">num_batches</span>

        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">eval_kpi_vals</span><span class="p">)</span></div>

<div class="viewcode-block" id="TrainEvalHandle.device_of"><a class="viewcode-back" href="../../../../../apiref/generated/hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.html#hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle.device_of">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">device_of</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the device of the given pytorch model.</span>
<span class="sd">        Distributed models are not supported.&quot;&quot;&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span> \
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
        <span class="k">return</span> <span class="n">device</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Continental Automotive GmbH

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>