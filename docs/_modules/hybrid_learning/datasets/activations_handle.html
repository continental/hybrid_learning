<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>hybrid_learning.datasets.activations_handle &mdash; hybrid_learning  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/autoclasstoc.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> hybrid_learning
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Content</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../quickstart/index.html">Quickstart Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../userguide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../apiref/index.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contributing.html">How to contribute</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">hybrid_learning</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>hybrid_learning.datasets.activations_handle</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for hybrid_learning.datasets.activations_handle</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Wrapper dealing with generating and caching activation maps from a dataset.</span>
<span class="sd">Useful for concept embedding analysis for easy reuse of generated activation maps.&quot;&quot;&quot;</span>

<span class="c1">#  Copyright (c) 2022 Continental Automotive GmbH</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Sequence</span>

<span class="kn">import</span> <span class="nn">PIL.Image</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Subset</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">caching</span>
<span class="kn">from</span> <span class="nn">.base</span> <span class="kn">import</span> <span class="n">BaseDataset</span>


<div class="viewcode-block" id="DatasetWrapper"><a class="viewcode-back" href="../../../apiref/generated/hybrid_learning.datasets.activations_handle.DatasetWrapper.html#hybrid_learning.datasets.activations_handle.DatasetWrapper">[docs]</a><span class="k">class</span> <span class="nc">DatasetWrapper</span><span class="p">(</span><span class="n">BaseDataset</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrap a dataset or subset to add caches or transforms.</span>
<span class="sd">    Wrapping a dataset with a :py:class:`DatasetWrapper` has the same effect</span>
<span class="sd">    as the in-place version</span>

<span class="sd">    .. code:: python</span>

<span class="sd">        dataset.transforms_cache = new_cache + cache</span>
<span class="sd">        dataset.transforms = transforms + new_transforms</span>

<span class="sd">    but without changing the wrapped dataset.</span>
<span class="sd">    In case the data is a :py:class:`torch.utils.data.Subset` instance,</span>
<span class="sd">    care is taken to correctly retrieve the descriptor of the subsetted</span>
<span class="sd">    data (without mixing up indices), see :py:meth:`descriptor`.</span>

<span class="sd">    .. note::</span>
<span class="sd">        :py:attr:`dataset` is read-only, and the dataset should not be</span>
<span class="sd">        changed. Create a new wrapper if this is necessary.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Subset</span><span class="p">,</span> <span class="n">BaseDataset</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;The wrapped dataset.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span>

<div class="viewcode-block" id="DatasetWrapper.__init__"><a class="viewcode-back" href="../../../apiref/generated/hybrid_learning.datasets.activations_handle.DatasetWrapper.html#hybrid_learning.datasets.activations_handle.DatasetWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Subset</span><span class="p">,</span> <span class="n">BaseDataset</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">],</span>
                 <span class="o">**</span><span class="n">data_args</span>
                 <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Init.</span>

<span class="sd">        :param dataset: Dataset to wrap; must be a sequence of tuples of</span>
<span class="sd">            ``(image, ground_truth)`` with both image and ground-truth</span>
<span class="sd">            of type :py:class:`torch.Tensor`;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># region Default values and value checks</span>
        <span class="n">data_args</span><span class="p">[</span><span class="s1">&#39;split&#39;</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">data_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;split&#39;</span><span class="p">,</span>
                          <span class="c1"># dataset.split</span>
                          <span class="nb">getattr</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="s2">&quot;split&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span>
                          <span class="c1"># dataset.dataset.split</span>
                          <span class="nb">getattr</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="s2">&quot;dataset&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                                  <span class="s2">&quot;split&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
        <span class="n">data_args</span><span class="p">[</span><span class="s1">&#39;dataset_root&#39;</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">data_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;dataset_root&#39;</span><span class="p">,</span>
                          <span class="c1"># dataset.dataset_root</span>
                          <span class="nb">getattr</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="s2">&quot;dataset_root&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span>
                          <span class="c1"># dataset.dataset.dataset_root</span>
                          <span class="nb">getattr</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="s2">&quot;dataset&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                                  <span class="s2">&quot;dataset_root&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">data_args</span><span class="p">[</span><span class="s1">&#39;dataset_root&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">((</span><span class="s2">&quot;dataset_root is None: not given and not &quot;</span>
                              <span class="s2">&quot;specified by dataset </span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">repr</span><span class="p">(</span><span class="n">dataset</span><span class="p">)))</span>
        <span class="c1"># endregion</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">data_args</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Subset</span><span class="p">,</span> <span class="n">BaseDataset</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span>
        <span class="sd">&quot;&quot;&quot;The wrapped dataset.&quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="DatasetWrapper.__len__"><a class="viewcode-back" href="../../../apiref/generated/hybrid_learning.datasets.activations_handle.DatasetWrapper.html#hybrid_learning.datasets.activations_handle.DatasetWrapper.__len__">[docs]</a>    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Length determined by the length of the wrapped dataset.</span>
<span class="sd">        See :py:attr:`dataset`.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span></div>

<div class="viewcode-block" id="DatasetWrapper.getitem"><a class="viewcode-back" href="../../../apiref/generated/hybrid_learning.datasets.activations_handle.DatasetWrapper.html#hybrid_learning.datasets.activations_handle.DatasetWrapper.getitem">[docs]</a>    <span class="k">def</span> <span class="nf">getitem</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span>
                <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">],</span>
                           <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">,</span>
                                 <span class="n">Dict</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">]]]:</span>
        <span class="sd">&quot;&quot;&quot;Wrap the __getitem__ of the wrapped dataset.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span></div>

<div class="viewcode-block" id="DatasetWrapper.descriptor"><a class="viewcode-back" href="../../../apiref/generated/hybrid_learning.datasets.activations_handle.DatasetWrapper.html#hybrid_learning.datasets.activations_handle.DatasetWrapper.descriptor">[docs]</a>    <span class="k">def</span> <span class="nf">descriptor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Wrap descriptor method of wrapped dataset.</span>
<span class="sd">        It is assumed that either :py:attr:`dataset` or</span>
<span class="sd">        ``self.dataset.dataset`` provide a function</span>
<span class="sd">        ``descriptor(i: int)``. This is e.g. the case for a</span>
<span class="sd">        :py:class:`hybrid_learning.datasets.base.BaseDataset` or a</span>
<span class="sd">        :py:class:`torch.utils.data.Subset` instance.</span>
<span class="sd">        In case of a subset instance, care is taken to heed the index shuffling.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">desc</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># For standard BaseDataset -&gt; use dataset descriptor</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="s2">&quot;descriptor&quot;</span><span class="p">)</span> \
                <span class="ow">and</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">descriptor</span><span class="p">):</span>
            <span class="c1"># noinspection PyTypeChecker</span>
            <span class="n">desc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">descriptor</span>
        <span class="c1"># Dataset wrapped in Subset -&gt; take care of index permutation</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="n">Subset</span><span class="p">)</span> \
                <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="s2">&quot;descriptor&quot;</span><span class="p">)</span> \
                <span class="ow">and</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">descriptor</span><span class="p">):</span>
            <span class="n">desc</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">idx</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">descriptor</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">indices</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">desc</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                <span class="p">(</span><span class="s2">&quot;Could not find descriptor() method within self.dataset &quot;</span>
                 <span class="s2">&quot;nor its dataset member; dataset type: </span><span class="si">{}</span><span class="s2">&quot;</span>
                 <span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">desc</span><span class="p">(</span><span class="n">i</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="ActivationDatasetWrapper"><a class="viewcode-back" href="../../../apiref/generated/hybrid_learning.datasets.activations_handle.ActivationDatasetWrapper.html#hybrid_learning.datasets.activations_handle.ActivationDatasetWrapper">[docs]</a><span class="k">class</span> <span class="nc">ActivationDatasetWrapper</span><span class="p">(</span><span class="n">DatasetWrapper</span><span class="p">):</span>
    <span class="c1"># noinspection PyUnresolvedReferences</span>
    <span class="sd">&quot;&quot;&quot;Wrapper for image datasets that will generate and yield activation maps.</span>
<span class="sd">    Behaves like a sequence of tuples of</span>

<span class="sd">    - activation maps (original input transformed by</span>
<span class="sd">        :py:attr:`generate_act_map`) and</span>
<span class="sd">    - original ground truth (e.g. mask)</span>

<span class="sd">    The wrapper can handle :py:class:`torch.utils.data.Subset` and</span>
<span class="sd">    :py:class:`hybrid_learning.datasets.base.BaseDataset` instances.</span>

<span class="sd">    Features:</span>

<span class="sd">    - Option to enable efficient file caching of the generated activation</span>
<span class="sd">      maps in order to avoid costly re-evaluations.</span>
<span class="sd">      See :py:attr:`act_maps_cache`.</span>
<span class="sd">    - Convenience functions for caching:</span>
<span class="sd">      :py:meth:`existence checks &lt;act_map_exists&gt;` and</span>
<span class="sd">      :py:meth:`cache filling &lt;fill_cache&gt;` with progress bar.</span>
<span class="sd">    - Replacement of the :py:attr:`activation generator &lt;generate_act_map&gt;` by</span>
<span class="sd">      the cache, i.e. no ``act_map_gen`` must be provided if activation maps</span>
<span class="sd">      for all indices are cached (make sure to not clear the cache then though).</span>

<span class="sd">    Activation map caching is enabled by setting :py:attr:`activations_root`</span>
<span class="sd">    and disabled by setting :py:attr:`activations_root` to ``None``.</span>
<span class="sd">    To fill the cache i.e. generate all activation maps, call</span>
<span class="sd">    :py:meth:`fill_cache`. But be aware that this can be very time</span>
<span class="sd">    consuming depending on the generator.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">activations_root</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;The activations root of the file cache if caching is enable.</span>
<span class="sd">        Enable caching by setting this to a file path, disable caching</span>
<span class="sd">        by setting this attribute to ``None``.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_maps_cache</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_maps_cache</span><span class="o">.</span><span class="n">cache_root</span>

    <span class="nd">@activations_root</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">activations_root</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">activations_root</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot;Disable activation map file caching.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act_maps_cache</span><span class="p">:</span> <span class="n">caching</span><span class="o">.</span><span class="n">PTCache</span> <span class="o">=</span> \
            <span class="n">caching</span><span class="o">.</span><span class="n">PTCache</span><span class="p">(</span><span class="n">activations_root</span><span class="p">)</span> <span class="k">if</span> <span class="n">activations_root</span> <span class="k">else</span> <span class="kc">None</span>

<div class="viewcode-block" id="ActivationDatasetWrapper.__init__"><a class="viewcode-back" href="../../../apiref/generated/hybrid_learning.datasets.activations_handle.ActivationDatasetWrapper.html#hybrid_learning.datasets.activations_handle.ActivationDatasetWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">BaseDataset</span><span class="p">,</span>
                 <span class="n">act_map_gen</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">activations_root</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">device</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">data_args</span><span class="p">):</span>
        <span class="c1"># pylint: disable=line-too-long</span>
        <span class="sd">&quot;&quot;&quot;Init.</span>

<span class="sd">        The base settings (dataset root, split) default to those of the</span>
<span class="sd">        wrapped dataset.</span>

<span class="sd">        :param dataset: Dataset to wrap; must be a sequence of tuples of</span>
<span class="sd">            ``(image, ground_truth)`` with both image and ground-truth</span>
<span class="sd">            of type :py:class:`torch.Tensor`;</span>
<span class="sd">            the default transformation assumes that the ground truth are masks</span>
<span class="sd">            (same sized images)</span>
<span class="sd">        :param act_map_gen: torch module that accepts as input a batch of</span>
<span class="sd">            images and returns the activation maps to yield</span>
<span class="sd">        :param activations_root: root directory under which to store and find</span>
<span class="sd">            the activation maps if file caching shall be enabled</span>
<span class="sd">        :param device: the device on which to run ``act_map_gen``;</span>
<span class="sd">            see :py:class:`hybrid_learning.datasets.transforms.image_transforms.ToActMap`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># pylint: enable=line-too-long</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="o">**</span><span class="n">data_args</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">act_maps_cache</span><span class="p">:</span> <span class="n">caching</span><span class="o">.</span><span class="n">PTCache</span> <span class="o">=</span> \
            <span class="n">caching</span><span class="o">.</span><span class="n">PTCache</span><span class="p">(</span><span class="n">activations_root</span><span class="p">)</span> <span class="k">if</span> <span class="n">activations_root</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="sd">&quot;&quot;&quot;File cache for caching activations.</span>
<span class="sd">        Set to ``None`` in case the activations root is set to ``False``</span>
<span class="sd">        during init.&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">generate_act_map</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> \
            <span class="p">(</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToActMap</span><span class="p">(</span><span class="n">act_map_gen</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
             <span class="k">if</span> <span class="n">act_map_gen</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
        <span class="sd">&quot;&quot;&quot;Transformation that returns an activation map given a valid input</span>
<span class="sd">        datum.</span>
<span class="sd">        Input data is assumed to origin from the original</span>
<span class="sd">        :py:attr:`~DatasetWrapper.dataset`.</span>
<span class="sd">        Used to generate missing activation maps in :py:meth:`getitem`.&quot;&quot;&quot;</span></div>

<div class="viewcode-block" id="ActivationDatasetWrapper.getitem"><a class="viewcode-back" href="../../../apiref/generated/hybrid_learning.datasets.activations_handle.ActivationDatasetWrapper.html#hybrid_learning.datasets.activations_handle.ActivationDatasetWrapper.getitem">[docs]</a>    <span class="k">def</span> <span class="nf">getitem</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Get activation map and original ground truth for item at index ``i``.</span>

<span class="sd">        Used for</span>
<span class="sd">        :py:meth:`~hybrid_learning.datasets.base.BaseDataset.__getitem__`.</span>
<span class="sd">        If the activation map does not exist and a generator is given in</span>
<span class="sd">        :py:attr:`generate_act_map`, generate and save the activation map.</span>

<span class="sd">        :return: tuple of the loaded or generated activation map and the</span>
<span class="sd">            target of the original dataset for that act map</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get mask</span>
        <span class="n">img_t</span><span class="p">,</span> <span class="n">mask_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_maps_cache</span><span class="p">:</span>
            <span class="n">desc</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">descriptor</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">act_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_maps_cache</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">desc</span><span class="p">)</span>

            <span class="c1"># Get activation map (generate and save lazily if possible)</span>
            <span class="k">if</span> <span class="n">act_map</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_act_map</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="p">(</span><span class="s2">&quot;generate_act_map unset but act map at index </span><span class="si">{}</span><span class="s2"> &quot;</span>
                         <span class="s2">&quot;missing from root directory </span><span class="si">{}</span><span class="s2"> (assumed path </span><span class="si">{}</span><span class="s2">).&quot;</span>
                         <span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_maps_cache</span><span class="o">.</span><span class="n">cache_root</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">act_map_filepath</span><span class="p">(</span><span class="n">i</span><span class="p">)))</span>
                <span class="n">act_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_act_map</span><span class="p">(</span><span class="n">img_t</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">act_maps_cache</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">desc</span><span class="p">,</span> <span class="n">act_map</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_act_map</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;generate_act_map unset but called&quot;</span><span class="p">)</span>
            <span class="n">act_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_act_map</span><span class="p">(</span><span class="n">img_t</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">act_map</span><span class="p">,</span> <span class="n">mask_t</span></div>

<div class="viewcode-block" id="ActivationDatasetWrapper.act_map_filepath"><a class="viewcode-back" href="../../../apiref/generated/hybrid_learning.datasets.activations_handle.ActivationDatasetWrapper.html#hybrid_learning.datasets.activations_handle.ActivationDatasetWrapper.act_map_filepath">[docs]</a>    <span class="k">def</span> <span class="nf">act_map_filepath</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the path to the activation map file in the cache.</span>
<span class="sd">        The base directory is :py:attr:`activations_root`.</span>
<span class="sd">        The basename is determined by the :py:attr:`act_maps_cache` from</span>
<span class="sd">        the ``descriptor()`` for the index ``i``.</span>

<span class="sd">        :param i: index of the image to get activation map for.</span>
<span class="sd">        :return: (relative or absolute) path to the activation map for datum</span>
<span class="sd">            at index ``i``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_maps_cache</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;act_map_filepath called but act_maps_cache is &quot;</span>
                               <span class="s2">&quot;unset&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_maps_cache</span><span class="o">.</span><span class="n">descriptor_to_fp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">descriptor</span><span class="p">(</span><span class="n">i</span><span class="p">))</span></div>

<div class="viewcode-block" id="ActivationDatasetWrapper.act_map_exists"><a class="viewcode-back" href="../../../apiref/generated/hybrid_learning.datasets.activations_handle.ActivationDatasetWrapper.html#hybrid_learning.datasets.activations_handle.ActivationDatasetWrapper.act_map_exists">[docs]</a>    <span class="k">def</span> <span class="nf">act_map_exists</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Check whether the activation map at index ``i`` is cached.</span>

<span class="sd">        :param i: index in :py:attr:`~DatasetWrapper.dataset` for which to check</span>
<span class="sd">            whether an activation map was created.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_maps_cache</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">act_fp</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_map_filepath</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">act_fp</span><span class="p">)</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">act_fp</span><span class="p">)</span></div>

<div class="viewcode-block" id="ActivationDatasetWrapper.load_image"><a class="viewcode-back" href="../../../apiref/generated/hybrid_learning.datasets.activations_handle.ActivationDatasetWrapper.html#hybrid_learning.datasets.activations_handle.ActivationDatasetWrapper.load_image">[docs]</a>    <span class="k">def</span> <span class="nf">load_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Load the image/original input for index ``i``.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="ActivationDatasetWrapper.fill_cache"><a class="viewcode-back" href="../../../apiref/generated/hybrid_learning.datasets.activations_handle.ActivationDatasetWrapper.html#hybrid_learning.datasets.activations_handle.ActivationDatasetWrapper.fill_cache">[docs]</a>    <span class="k">def</span> <span class="nf">fill_cache</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">force_rebuild</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                   <span class="n">show_progress_bar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                   <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;ActivationDatasetWrapper&#39;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Generate activation maps for all images.</span>

<span class="sd">        :param force_rebuild: whether to overwrite existing images or not</span>
<span class="sd">        :param show_progress_bar: whether to show the progress using</span>
<span class="sd">            :py:class:`tqdm.tqdm`</span>
<span class="sd">        :param kwargs: further arguments to the progress bar</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># region Value check</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_maps_cache</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Act maps cannot be generated while &quot;</span>
                             <span class="s2">&quot;act_maps_cache is unset.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_act_map</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Act maps cannot be generated if &quot;</span>
                             <span class="s2">&quot;generate_act_map is unset.&quot;</span><span class="p">)</span>
        <span class="c1"># endregion</span>

        <span class="n">act_maps_to_process</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
                               <span class="k">if</span> <span class="n">force_rebuild</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">act_map_exists</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">act_maps_to_process</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="k">if</span> <span class="n">show_progress_bar</span><span class="p">:</span>
            <span class="n">act_maps_to_process</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span>
                <span class="o">**</span><span class="p">{</span><span class="o">**</span><span class="nb">dict</span><span class="p">(</span><span class="n">iterable</span><span class="o">=</span><span class="n">act_maps_to_process</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;act_map&quot;</span><span class="p">,</span>
                          <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Activation maps newly generated: &quot;</span><span class="p">),</span>
                   <span class="o">**</span><span class="n">kwargs</span><span class="p">})</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">act_maps_to_process</span><span class="p">:</span>
            <span class="c1"># Get activation map</span>
            <span class="n">desc</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">descriptor</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">img_t</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_image</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">act_map</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_act_map</span><span class="p">(</span><span class="n">img_t</span><span class="p">)</span>

            <span class="c1"># Save</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">act_maps_cache</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">desc</span><span class="p">,</span> <span class="n">act_map</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Continental Automotive GmbH.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>