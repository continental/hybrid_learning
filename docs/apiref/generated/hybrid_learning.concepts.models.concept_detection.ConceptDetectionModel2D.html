

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>ConceptDetectionModel2D &mdash; hybrid_learning  documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/autoclasstoc.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="concept_segmentation" href="hybrid_learning.concepts.models.concept_segmentation.html" />
    <link rel="prev" title="ConceptDetection2DTrainTestHandle" href="hybrid_learning.concepts.models.concept_detection.ConceptDetection2DTrainTestHandle.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> hybrid_learning
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Content</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../quickstart/index.html">Quickstart Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../userguide/index.html">User Guide</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="hybrid_learning.concepts.html">concepts</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="hybrid_learning.concepts.analysis.html">analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="hybrid_learning.concepts.concepts.html">concepts</a></li>
<li class="toctree-l3"><a class="reference internal" href="hybrid_learning.concepts.embeddings.html">embeddings</a></li>
<li class="toctree-l3"><a class="reference internal" href="hybrid_learning.concepts.enforcement.html">enforcement</a></li>
<li class="toctree-l3"><a class="reference internal" href="hybrid_learning.concepts.kpis.html">kpis</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="hybrid_learning.concepts.models.html">models</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="hybrid_learning.concepts.models.base_handles.html">base_handles</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="hybrid_learning.concepts.models.concept_detection.html">concept_detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="hybrid_learning.concepts.models.concept_segmentation.html">concept_segmentation</a></li>
<li class="toctree-l4"><a class="reference internal" href="hybrid_learning.concepts.models.model_extension.html">model_extension</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="hybrid_learning.concepts.visualization.html">visualization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="hybrid_learning.datasets.html">datasets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">How to contribute</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">hybrid_learning</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../index.html">API Reference</a> &raquo;</li>
        
          <li><a href="hybrid_learning.concepts.html">concepts</a> &raquo;</li>
        
          <li><a href="hybrid_learning.concepts.models.html">models</a> &raquo;</li>
        
          <li><a href="hybrid_learning.concepts.models.concept_detection.html">concept_detection</a> &raquo;</li>
        
      <li>ConceptDetectionModel2D</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/apiref/generated/hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="conceptdetectionmodel2d">
<h1>ConceptDetectionModel2D<a class="headerlink" href="#conceptdetectionmodel2d" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt id="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D">
<em class="property">class </em><code class="sig-prename descclassname">hybrid_learning.concepts.models.concept_detection.</code><code class="sig-name descname">ConceptDetectionModel2D</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">concept</span></em>, <em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">layer_id</span></em>, <em class="sig-param"><span class="n">kernel_size</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">in_channels</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">concept_name</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/concept_detection.html#ConceptDetectionModel2D"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Pytorch model implementation of a concept embedding for 2D conv layers.
The model itself simply is a convolutional layer with sigmoid activation.
The goal of this model is to tell from an activation map, which spatial
“parts” of the activation map belong to a given concept and which not.
These parts are windows of the concept model <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size"><code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></a>.</p>
<p>The model features training and evaluation functionality for concept
analysis, i.e. for training this concept module on the activation map output
of the given model and layer without changing the main model.</p>
<p>When the model forward works as follows:</p>
<dl class="field-list simple">
<dt class="field-odd">Input</dt>
<dd class="field-odd"><p>Activation map output of a 2D convolutional layer.</p>
</dd>
<dt class="field-even">Output</dt>
<dd class="field-even"><p>Heatmap showing which centers of boxes of <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size"><code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></a> belong
to <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept"><code class="xref py py-attr docutils literal notranslate"><span class="pre">concept</span></code></a>.
The heatmap values are the sigmoid of a convolution operation.</p>
</dd>
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>concept</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="hybrid_learning.concepts.concepts.SegmentationConcept2D.html#hybrid_learning.concepts.concepts.SegmentationConcept2D" title="hybrid_learning.concepts.concepts.SegmentationConcept2D"><em>hybrid_learning.concepts.concepts.SegmentationConcept2D</em></a><em>]</em>) – </p></li>
<li><p><strong>model</strong> (<em>Optional</em><em>[</em><em>torch.nn.modules.module.Module</em><em>]</em>) – </p></li>
<li><p><strong>layer_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – </p></li>
<li><p><strong>kernel_size</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p></li>
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – </p></li>
<li><p><strong>concept_name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – </p></li>
</ul>
</dd>
</dl>
<p>Init.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>Optional</em><em>[</em><em>torch.nn.modules.module.Module</em><em>]</em>) – model the concept should be embedded in;
used to create (and later accessible in)
<a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model_stump" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model_stump"><code class="xref py py-attr docutils literal notranslate"><span class="pre">main_model_stump</span></code></a>;
used for <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size"><code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></a> and <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.in_channels" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.in_channels"><code class="xref py py-attr docutils literal notranslate"><span class="pre">in_channels</span></code></a>
auto-inference</p></li>
<li><p><strong>layer_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – the layer index in
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict" title="(in PyTorch vmaster (1.6.0a0+4392e52 ))"><code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code></a>, the output of which is to
be fed to the the concept model; used to create (and later
accessible) in <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model_stump" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model_stump"><code class="xref py py-attr docutils literal notranslate"><span class="pre">main_model_stump</span></code></a>;
used for <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size"><code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></a> and <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.in_channels" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.in_channels"><code class="xref py py-attr docutils literal notranslate"><span class="pre">in_channels</span></code></a>
auto-inference</p></li>
<li><p><strong>concept</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="hybrid_learning.concepts.concepts.SegmentationConcept2D.html#hybrid_learning.concepts.concepts.SegmentationConcept2D" title="hybrid_learning.concepts.concepts.SegmentationConcept2D"><em>hybrid_learning.concepts.concepts.SegmentationConcept2D</em></a><em>]</em>) – Concept to train for; must be a segmentation concept
featuring ground truth masks; used for <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size"><code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></a> and
<a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.in_channels" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.in_channels"><code class="xref py py-attr docutils literal notranslate"><span class="pre">in_channels</span></code></a> auto-inference</p></li>
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of filters of the
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="(in PyTorch vmaster (1.6.0a0+4392e52 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Conv2d</span></code></a>-Layer to analyse;
the value is automatically determined if <code class="docutils literal notranslate"><span class="pre">in_channels</span></code> or
<code class="docutils literal notranslate"><span class="pre">kernel_size</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>;
an automatically generated value overwrites a given value with a
warning</p></li>
<li><p><strong>kernel_size</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Size in activation map pixels of a window for
which to assess whether it is part of the <code class="docutils literal notranslate"><span class="pre">concept</span></code> or not;
by default it is determined by the relative sizes in the concept’s
<a class="reference internal" href="hybrid_learning.concepts.concepts.SegmentationConcept2D.html#hybrid_learning.concepts.concepts.SegmentationConcept2D.rel_size" title="hybrid_learning.concepts.concepts.SegmentationConcept2D.rel_size"><code class="xref py py-attr docutils literal notranslate"><span class="pre">rel_size</span></code></a>
and the layer output size;
if <code class="docutils literal notranslate"><span class="pre">concept.rel_size</span></code> is not set, <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size"><code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></a> is set to
<code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">1)</span></code> with a warning</p></li>
<li><p><strong>concept_name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The default value for the <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept_name" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept_name"><code class="xref py py-attr docutils literal notranslate"><span class="pre">concept_name</span></code></a>
property if <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept"><code class="xref py py-attr docutils literal notranslate"><span class="pre">concept</span></code></a> is <code class="docutils literal notranslate"><span class="pre">None</span></code>; serves as ID for
the concept model</p></li>
</ul>
</dd>
</dl>
<div class="autoclasstoc docutils container">
<p class="rubric">Public Data Attributes:</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept"><code class="xref py py-obj docutils literal notranslate"><span class="pre">concept</span></code></a></p></td>
<td><p>The concept (data) for which this model is/should be trained.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept_name" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept_name"><code class="xref py py-obj docutils literal notranslate"><span class="pre">concept_name</span></code></a></p></td>
<td><p>The name of the associated concept if known.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model_stump" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model_stump"><code class="xref py py-obj docutils literal notranslate"><span class="pre">main_model_stump</span></code></a></p></td>
<td><p>Stump of the main model in the head of which to localize the concept embedding.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">main_model</span></code></a></p></td>
<td><p>Shortcut to access the main model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.layer_id" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.layer_id"><code class="xref py py-obj docutils literal notranslate"><span class="pre">layer_id</span></code></a></p></td>
<td><p>Layer to extract concept from.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kernel_size</span></code></a></p></td>
<td><p>Size of the convolution kernel.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.in_channels" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.in_channels"><code class="xref py py-obj docutils literal notranslate"><span class="pre">in_channels</span></code></a></p></td>
<td><p>Number of input channels.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.settings" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.settings"><code class="xref py py-obj docutils literal notranslate"><span class="pre">settings</span></code></a></p></td>
<td><p>The current model settings as dictionary.</p></td>
</tr>
</tbody>
</table>
<details><summary>Inherited from <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></summary><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">dump_patches</span></code></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">T_destination</span></code></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</details></div>
<div class="autoclasstoc docutils container">
<p class="rubric">Public Methods:</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.reset_parameters" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.reset_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_parameters</span></code></a>()</p></td>
<td><p>Randomly (re)initialize weight and bias.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.to_embedding" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.to_embedding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_embedding</span></code></a>()</p></td>
<td><p>Return the plain representation as <a class="reference internal" href="hybrid_learning.concepts.embeddings.ConceptEmbedding.html#hybrid_learning.concepts.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.embeddings.ConceptEmbedding"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConceptEmbedding</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.forward" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(*inp)</p></td>
<td><p>Torch model forward evaluation method.</p></td>
</tr>
</tbody>
</table>
<details><summary>Inherited from <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></summary><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.forward" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(*inp)</p></td>
<td><p>Torch model forward evaluation method.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_buffer</span></code>(name, tensor[, persistent])</p></td>
<td><p>Adds a buffer to the module.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_parameter</span></code>(name, param)</p></td>
<td><p>Adds a parameter to the module.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_module</span></code>(name, module)</p></td>
<td><p>Adds a child module to the current module.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>) as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">cuda</span></code>([device])</p></td>
<td><p>Moves all model parameters and buffers to the GPU.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">cpu</span></code>()</p></td>
<td><p>Moves all model parameters and buffers to the CPU.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">type</span></code>(dst_type)</p></td>
<td><p>Casts all parameters and buffers to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dst_type</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>()</p></td>
<td><p>Casts all floating point parameters and buffers to float datatype.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">double</span></code>()</p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">double</span></code> datatype.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">half</span></code>()</p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">half</span></code> datatype.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">bfloat16</span></code>()</p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code>(*args, **kwargs)</p></td>
<td><p>Moves and/or casts the parameters and buffers.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_backward_hook</span></code>(hook)</p></td>
<td><p>Registers a backward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code>(hook)</p></td>
<td><p>Registers a forward pre-hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code>(hook)</p></td>
<td><p>Registers a forward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">T_destination</span></code></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_dict</span></code>([destination, prefix, keep_vars])</p></td>
<td><p>Returns a dictionary containing a whole state of the module.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_state_dict</span></code>(state_dict[, strict])</p></td>
<td><p>Copies parameters and buffers from <code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code> into this module and its descendants.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">parameters</span></code>([recurse])</p></td>
<td><p>Returns an iterator over module parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_parameters</span></code>([prefix, recurse])</p></td>
<td><p>Returns an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">buffers</span></code>([recurse])</p></td>
<td><p>Returns an iterator over module buffers.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_buffers</span></code>([prefix, recurse])</p></td>
<td><p>Returns an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">children</span></code>()</p></td>
<td><p>Returns an iterator over immediate children modules.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_children</span></code>()</p></td>
<td><p>Returns an iterator over immediate children modules, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">modules</span></code>()</p></td>
<td><p>Returns an iterator over all modules in the network.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_modules</span></code>([memo, prefix])</p></td>
<td><p>Returns an iterator over all modules in the network, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">train</span></code>([mode])</p></td>
<td><p>Sets the module in training mode.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">eval</span></code>()</p></td>
<td><p>Sets the module in evaluation mode.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">requires_grad_</span></code>([requires_grad])</p></td>
<td><p>Change if autograd should record operations on parameters in this module.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code>()</p></td>
<td><p>Sets gradients of all model parameters to zero.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_memory</span></code>()</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">extra_repr</span></code>()</p></td>
<td><p>Set the extra representation of the module</p></td>
</tr>
</tbody>
</table>
</details></div>
<div class="autoclasstoc docutils container">
<p class="rubric">Special Methods:</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.__init__" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.__init__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">__init__</span></code></a>(concept, model, layer_id[, …])</p></td>
<td><p>Init.</p></td>
</tr>
</tbody>
</table>
<details><summary>Inherited from <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></summary><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.__init__" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.__init__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">__init__</span></code></a>(concept, model, layer_id[, …])</p></td>
<td><p>Init.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__call__</span></code>(*input, **kwargs)</p></td>
<td><p>Call self as a function.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__setstate__</span></code>(state)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__getattr__</span></code>(name)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__setattr__</span></code>(name, value)</p></td>
<td><p>Implement setattr(self, name, value).</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__delattr__</span></code>(name)</p></td>
<td><p>Implement delattr(self, name).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__repr__</span></code>()</p></td>
<td><p>Return repr(self).</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">__dir__</span></code>()</p></td>
<td><p>default dir() implementation</p></td>
</tr>
</tbody>
</table>
</details></div>
<hr class="docutils" />
<dl class="py method">
<dt id="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">concept</span></em>, <em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">layer_id</span></em>, <em class="sig-param"><span class="n">kernel_size</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">in_channels</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">concept_name</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/concept_detection.html#ConceptDetectionModel2D.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Init.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>Optional</em><em>[</em><em>torch.nn.modules.module.Module</em><em>]</em>) – model the concept should be embedded in;
used to create (and later accessible in)
<a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model_stump" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model_stump"><code class="xref py py-attr docutils literal notranslate"><span class="pre">main_model_stump</span></code></a>;
used for <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size"><code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></a> and <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.in_channels" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.in_channels"><code class="xref py py-attr docutils literal notranslate"><span class="pre">in_channels</span></code></a>
auto-inference</p></li>
<li><p><strong>layer_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – the layer index in
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict" title="(in PyTorch vmaster (1.6.0a0+4392e52 ))"><code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code></a>, the output of which is to
be fed to the the concept model; used to create (and later
accessible) in <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model_stump" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model_stump"><code class="xref py py-attr docutils literal notranslate"><span class="pre">main_model_stump</span></code></a>;
used for <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size"><code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></a> and <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.in_channels" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.in_channels"><code class="xref py py-attr docutils literal notranslate"><span class="pre">in_channels</span></code></a>
auto-inference</p></li>
<li><p><strong>concept</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="hybrid_learning.concepts.concepts.SegmentationConcept2D.html#hybrid_learning.concepts.concepts.SegmentationConcept2D" title="hybrid_learning.concepts.concepts.SegmentationConcept2D"><em>hybrid_learning.concepts.concepts.SegmentationConcept2D</em></a><em>]</em>) – Concept to train for; must be a segmentation concept
featuring ground truth masks; used for <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size"><code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></a> and
<a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.in_channels" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.in_channels"><code class="xref py py-attr docutils literal notranslate"><span class="pre">in_channels</span></code></a> auto-inference</p></li>
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – Number of filters of the
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="(in PyTorch vmaster (1.6.0a0+4392e52 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Conv2d</span></code></a>-Layer to analyse;
the value is automatically determined if <code class="docutils literal notranslate"><span class="pre">in_channels</span></code> or
<code class="docutils literal notranslate"><span class="pre">kernel_size</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>;
an automatically generated value overwrites a given value with a
warning</p></li>
<li><p><strong>kernel_size</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – Size in activation map pixels of a window for
which to assess whether it is part of the <code class="docutils literal notranslate"><span class="pre">concept</span></code> or not;
by default it is determined by the relative sizes in the concept’s
<a class="reference internal" href="hybrid_learning.concepts.concepts.SegmentationConcept2D.html#hybrid_learning.concepts.concepts.SegmentationConcept2D.rel_size" title="hybrid_learning.concepts.concepts.SegmentationConcept2D.rel_size"><code class="xref py py-attr docutils literal notranslate"><span class="pre">rel_size</span></code></a>
and the layer output size;
if <code class="docutils literal notranslate"><span class="pre">concept.rel_size</span></code> is not set, <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size"><code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></a> is set to
<code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">1)</span></code> with a warning</p></li>
<li><p><strong>concept_name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – The default value for the <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept_name" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept_name"><code class="xref py py-attr docutils literal notranslate"><span class="pre">concept_name</span></code></a>
property if <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept"><code class="xref py py-attr docutils literal notranslate"><span class="pre">concept</span></code></a> is <code class="docutils literal notranslate"><span class="pre">None</span></code>; serves as ID for
the concept model</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">inp</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/concept_detection.html#ConceptDetectionModel2D.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Torch model forward evaluation method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inp</strong> (<em>Sequence</em><em>[</em><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+4392e52 ))"><em>torch.Tensor</em></a><em>]</em>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.from_embedding">
<em class="property">static </em><code class="sig-name descname">from_embedding</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">embedding</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">main_model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">concept</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/concept_detection.html#ConceptDetectionModel2D.from_embedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.from_embedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize a concept localization model from an embedding.
The weight and bias are obtained as follows:</p>
<dl class="field-list">
<dt class="field-odd">Weight</dt>
<dd class="field-odd"><p>The weight is the normal vector of the embedding</p>
</dd>
<dt class="field-even">Bias</dt>
<dd class="field-even"><p>Given the <code class="docutils literal notranslate"><span class="pre">embedding</span></code>’s
<a class="reference internal" href="hybrid_learning.concepts.embeddings.ConceptEmbedding.html#hybrid_learning.concepts.embeddings.ConceptEmbedding.support_factor" title="hybrid_learning.concepts.embeddings.ConceptEmbedding.support_factor"><code class="xref py py-attr docutils literal notranslate"><span class="pre">support_factor</span></code></a>
as <span class="math notranslate nohighlight">\(b\)</span>, the bias calculates as
(compare <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.to_embedding" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.to_embedding"><code class="xref py py-meth docutils literal notranslate"><span class="pre">to_embedding()</span></code></a>):</p>
<div class="math notranslate nohighlight">
\[\text{bias} = - b \cdot (|\text{weight}|^2)\]</div>
</dd>
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embedding</strong> (<a class="reference internal" href="hybrid_learning.concepts.embeddings.ConceptEmbedding.html#hybrid_learning.concepts.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.embeddings.ConceptEmbedding"><em>hybrid_learning.concepts.embeddings.ConceptEmbedding</em></a>) – the embedding to use</p></li>
<li><p><strong>main_model</strong> (<em>torch.nn.modules.module.Module</em>) – <code class="docutils literal notranslate"><span class="pre">main_model</span></code> to use for init of the new
<a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConceptDetectionModel2D</span></code></a>; defaults to the <code class="docutils literal notranslate"><span class="pre">embedding</span></code>’s
<a class="reference internal" href="hybrid_learning.concepts.embeddings.ConceptEmbedding.html#hybrid_learning.concepts.embeddings.ConceptEmbedding.main_model" title="hybrid_learning.concepts.embeddings.ConceptEmbedding.main_model"><code class="xref py py-attr docutils literal notranslate"><span class="pre">main_model</span></code></a></p></li>
<li><p><strong>concept</strong> (<a class="reference internal" href="hybrid_learning.concepts.concepts.SegmentationConcept2D.html#hybrid_learning.concepts.concepts.SegmentationConcept2D" title="hybrid_learning.concepts.concepts.SegmentationConcept2D"><em>hybrid_learning.concepts.concepts.SegmentationConcept2D</em></a>) – <code class="docutils literal notranslate"><span class="pre">concept</span></code> to use for init of the new
<a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConceptDetectionModel2D</span></code></a>
must be valid input to the
<a class="reference internal" href="hybrid_learning.concepts.concepts.Concept.html#hybrid_learning.concepts.concepts.Concept.new" title="hybrid_learning.concepts.concepts.Concept.new"><code class="xref py py-meth docutils literal notranslate"><span class="pre">new()</span></code></a> method
of the
<a class="reference internal" href="hybrid_learning.concepts.concepts.SegmentationConcept2D.html#hybrid_learning.concepts.concepts.SegmentationConcept2D" title="hybrid_learning.concepts.concepts.SegmentationConcept2D"><code class="xref py py-meth docutils literal notranslate"><span class="pre">SegmentationConcept2D()</span></code></a>
class; defaults to the <code class="docutils literal notranslate"><span class="pre">embedding</span></code>’s
<a class="reference internal" href="hybrid_learning.concepts.embeddings.ConceptEmbedding.html#hybrid_learning.concepts.embeddings.ConceptEmbedding.concept" title="hybrid_learning.concepts.embeddings.ConceptEmbedding.concept"><code class="xref py py-attr docutils literal notranslate"><span class="pre">concept</span></code></a></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a concept localization model initialized with the embedding
information</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D">hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/concept_detection.html#ConceptDetectionModel2D.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Randomly (re)initialize weight and bias.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/constants.html#None" title="(in Python v3.6)">None</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.to_embedding">
<code class="sig-name descname">to_embedding</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/concept_detection.html#ConceptDetectionModel2D.to_embedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.to_embedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the plain representation as
<a class="reference internal" href="hybrid_learning.concepts.embeddings.ConceptEmbedding.html#hybrid_learning.concepts.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.embeddings.ConceptEmbedding"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConceptEmbedding</span></code></a>.
I.e.</p>
<dl class="field-list simple">
<dt class="field-odd">As parameters</dt>
<dd class="field-odd"><p>weight and bias of <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept_layer" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept_layer"><code class="xref py py-attr docutils literal notranslate"><span class="pre">concept_layer</span></code></a>, and</p>
</dd>
<dt class="field-even">As meta info</dt>
<dd class="field-even"><p>the <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept"><code class="xref py py-attr docutils literal notranslate"><span class="pre">concept</span></code></a> and <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model"><code class="xref py py-attr docutils literal notranslate"><span class="pre">main_model</span></code></a>
with <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.layer_id" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.layer_id"><code class="xref py py-attr docutils literal notranslate"><span class="pre">layer_id</span></code></a>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="hybrid_learning.concepts.embeddings.ConceptEmbedding.html#hybrid_learning.concepts.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.embeddings.ConceptEmbedding">hybrid_learning.concepts.embeddings.ConceptEmbedding</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This must be a deep copy to avoid overwriting in a consecutive
training session.</p>
</div>
<p>The resulting embedding describes the decision hyperplane of the
concept model. Its normal vector <span class="math notranslate nohighlight">\(n\)</span> is the concept layer weight.
The orthogonal support vector given by <span class="math notranslate nohighlight">\(b\cdot n\)</span> for a scalar
factor <span class="math notranslate nohighlight">\(b\)</span> must fulfill</p>
<div class="math notranslate nohighlight">
\[\forall v: (v - b\cdot n) \circ n
= d(v)
= (v \circ \text{weight}) + \text{bias}\]</div>
<p>i.e.</p>
<div class="math notranslate nohighlight">
\[n = \text{weight} \quad\text{and}\quad
b = - \frac{\text{bias}} {|\text{weight}|^2}.\]</div>
<p>Here, <span class="math notranslate nohighlight">\(d(v)\)</span> is the signed distance measure of a vector
from the hyperplane, i.e.</p>
<div class="math notranslate nohighlight">
\[\begin{split}d(v)
\begin{cases}
    &gt; 0  &amp; \text{iff vector yields a positive prediction,}\\
    \equiv 0 &amp; \text{iff vector on decision boundary hyperplane,}\\
    &lt; 0  &amp; \text{iff vector yields a negative prediction.}
\end{cases}\end{split}\]</div>
</dd></dl>

<dl class="py attribute">
<dt id="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.activation">
<code class="sig-name descname">activation</code><a class="headerlink" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.activation" title="Permalink to this definition">¶</a></dt>
<dd><p>The sigmoid activation layer to obtain heatmaps in <code class="docutils literal notranslate"><span class="pre">[0,1]</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt id="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept">
<em class="property">property </em><code class="sig-name descname">concept</code><a class="headerlink" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept" title="Permalink to this definition">¶</a></dt>
<dd><p>The concept (data) for which this model is/should be trained.</p>
</dd></dl>

<dl class="py attribute">
<dt id="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept_layer">
<code class="sig-name descname">concept_layer</code><a class="headerlink" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept_layer" title="Permalink to this definition">¶</a></dt>
<dd><p>The Conv layer which is trained to detect windows
in which concept is located.
The number of input channels is automatically determined if not given
as <code class="docutils literal notranslate"><span class="pre">in_channels</span></code> in the <code class="docutils literal notranslate"><span class="pre">__init__</span></code> call.
(automatic determination requires one forward of the main model).</p>
</dd></dl>

<dl class="py method">
<dt id="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept_name">
<em class="property">property </em><code class="sig-name descname">concept_name</code><a class="headerlink" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.concept_name" title="Permalink to this definition">¶</a></dt>
<dd><p>The name of the associated concept if known.</p>
</dd></dl>

<dl class="py method">
<dt id="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.in_channels">
<em class="property">property </em><code class="sig-name descname">in_channels</code><a class="headerlink" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.in_channels" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of input channels.
This is the number of output channels of layer to investigate.</p>
</dd></dl>

<dl class="py method">
<dt id="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size">
<em class="property">property </em><code class="sig-name descname">kernel_size</code><a class="headerlink" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.kernel_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Size of the convolution kernel.
This is the assumed concept size in activation map pixels.</p>
</dd></dl>

<dl class="py method">
<dt id="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.layer_id">
<em class="property">property </em><code class="sig-name descname">layer_id</code><a class="headerlink" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.layer_id" title="Permalink to this definition">¶</a></dt>
<dd><p>Layer to extract concept from.
Shortcut to access the information from <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model_stump" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model_stump"><code class="xref py py-attr docutils literal notranslate"><span class="pre">main_model_stump</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt id="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model">
<em class="property">property </em><code class="sig-name descname">main_model</code><a class="headerlink" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Shortcut to access the main model.
It is wrapped by <a class="reference internal" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model_stump" title="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model_stump"><code class="xref py py-attr docutils literal notranslate"><span class="pre">main_model_stump</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt id="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model_stump">
<em class="property">property </em><code class="sig-name descname">main_model_stump</code><a class="headerlink" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.main_model_stump" title="Permalink to this definition">¶</a></dt>
<dd><p>Stump of the main model in the head of which to localize the
concept embedding.
Used to generate the activation maps needed for concept analysis
training. The actual attribute is wrapped into a tuple to hide the
parameters, since these shall not be updated; see
<a class="reference external" href="https://discuss.pytorch.org/t/how-to-exclude-parameters-from-model/6151">https://discuss.pytorch.org/t/how-to-exclude-parameters-from-model/6151</a></p>
</dd></dl>

<dl class="py method">
<dt id="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.settings">
<em class="property">property </em><code class="sig-name descname">settings</code><a class="headerlink" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.settings" title="Permalink to this definition">¶</a></dt>
<dd><p>The current model settings as dictionary.</p>
</dd></dl>

<dl class="py attribute">
<dt id="hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.training">
<code class="sig-name descname">training</code><em class="property">: <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)">bool</a></em><a class="headerlink" href="#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="hybrid_learning.concepts.models.concept_segmentation.html" class="btn btn-neutral float-right" title="concept_segmentation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="hybrid_learning.concepts.models.concept_detection.ConceptDetection2DTrainTestHandle.html" class="btn btn-neutral float-left" title="ConceptDetection2DTrainTestHandle" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Continental Automotive GmbH

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>