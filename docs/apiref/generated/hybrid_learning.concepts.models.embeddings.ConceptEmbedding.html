<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ConceptEmbedding &mdash; hybrid_learning  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/autoclasstoc.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="model_extension" href="hybrid_learning.concepts.models.model_extension.html" />
    <link rel="prev" title="embeddings" href="hybrid_learning.concepts.models.embeddings.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> hybrid_learning
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Content</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../quickstart/index.html">Quickstart Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../userguide/index.html">User Guide</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="hybrid_learning.concepts.html">concepts</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="hybrid_learning.concepts.analysis.html">analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="hybrid_learning.concepts.concepts.html">concepts</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="hybrid_learning.concepts.models.html">models</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="hybrid_learning.concepts.models.concept_models.html">concept_models</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="hybrid_learning.concepts.models.embeddings.html">embeddings</a></li>
<li class="toctree-l4"><a class="reference internal" href="hybrid_learning.concepts.models.model_extension.html">model_extension</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="hybrid_learning.concepts.train_eval.html">train_eval</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="hybrid_learning.datasets.html">datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="hybrid_learning.fuzzy_logic.html">fuzzy_logic</a></li>
<li class="toctree-l2"><a class="reference internal" href="hybrid_learning.experimentation.html">experimentation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">How to contribute</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">hybrid_learning</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">API Reference</a> &raquo;</li>
          <li><a href="hybrid_learning.concepts.html">concepts</a> &raquo;</li>
          <li><a href="hybrid_learning.concepts.models.html">models</a> &raquo;</li>
          <li><a href="hybrid_learning.concepts.models.embeddings.html">embeddings</a> &raquo;</li>
      <li>ConceptEmbedding</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/apiref/generated/hybrid_learning.concepts.models.embeddings.ConceptEmbedding.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="conceptembedding">
<h1>ConceptEmbedding<a class="headerlink" href="#conceptembedding" title="Permalink to this headline"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hybrid_learning.concepts.models.embeddings.</span></span><span class="sig-name descname"><span class="pre">ConceptEmbedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normal_vec_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scaling_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">meta_info</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Representation of an embedding of a concept within a DNN.
The representation aims to be technology independent.</p>
<p>Main aspects:</p>
<ul class="simple">
<li><p>the parameters:
<span class="math notranslate nohighlight">\(\text{concept vector} = \text{weight}\)</span>,
<span class="math notranslate nohighlight">\(\text{bias} = -\text{threshold}\)</span></p></li>
<li><p>the layer it is attached to given by the model up to that layer.</p></li>
</ul>
<div class="autoclasstoc docutils container">
<p class="rubric">Public Data Attributes:</p>
<table class="autosummary longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.settings" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.settings"><code class="xref py py-obj docutils literal notranslate"><span class="pre">settings</span></code></a></p></td>
<td><p>Dictionary to reproduce the instance.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.normal_vec" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.normal_vec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">normal_vec</span></code></a></p></td>
<td><p>A normal vector to the represented hyperplane.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.bias" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.bias"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bias</span></code></a></p></td>
<td><p>The bias <span class="math notranslate nohighlight">\(B\)</span> of the represented hyperplane.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.support_factor" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.support_factor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">support_factor</span></code></a></p></td>
<td><p>A factor <span class="math notranslate nohighlight">\(b\)</span> to obtain the orthogonal support vector <span class="math notranslate nohighlight">\(b\cdot n\)</span> from the normal vector <span class="math notranslate nohighlight">\(n\)</span>.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="autoclasstoc docutils container">
<p class="rubric">Public Methods:</p>
<table class="autosummary longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.scale" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.scale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scale</span></code></a>()</p></td>
<td><p>Return a new equivalent embedding with <code class="docutils literal notranslate"><span class="pre">scaling_factor</span> <span class="pre">==</span> <span class="pre">1</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.save" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(filepath[, overwrite])</p></td>
<td><p>Save the embedding parameters and some description as torch pt file.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.distance" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.distance"><code class="xref py py-obj docutils literal notranslate"><span class="pre">distance</span></code></a>(point)</p></td>
<td><p>Calc the scaled distance of point from the embedding hyperplane.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.normalize" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.normalize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">normalize</span></code></a>()</p></td>
<td><p>Yield a new, equivalent embedding with normalized normal vec.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.unique" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.unique"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unique</span></code></a>()</p></td>
<td><p>Yield new, equivalent, unique embedding with normalized normal vec and pos scaling.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.unique_upper_sphere" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.unique_upper_sphere"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unique_upper_sphere</span></code></a>()</p></td>
<td><p>Yield new equivalent, unique embedding with normal vec normalized in upper hemisphere.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.to_pos_scaling" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.to_pos_scaling"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_pos_scaling</span></code></a>()</p></td>
<td><p>Return the representation of this embedding with positive scaling.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.forget_scaling" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.forget_scaling"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forget_scaling</span></code></a>()</p></td>
<td><p>Return the embedding with the same normal vec and support but scaling factor 1.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="autoclasstoc docutils container">
<p class="rubric">Special Methods:</p>
<table class="autosummary longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__init__" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__init__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">__init__</span></code></a>(state_dict, kernel_size[, ...])</p></td>
<td><p>Init.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__getattr__" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__getattr__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">__getattr__</span></code></a>(key)</p></td>
<td><p>Hand over attribute access to meta_infos if necessary.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__eq__" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__eq__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">__eq__</span></code></a>(other)</p></td>
<td><p>Convert both embeddings to unique representation and compare values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__repr__" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__repr__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">__repr__</span></code></a>()</p></td>
<td><p>Information about concept, model, layer, concept vector and thresh.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__copy__" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__copy__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">__copy__</span></code></a>()</p></td>
<td><p>Return a copy of this embedding.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__deepcopy__" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__deepcopy__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">__deepcopy__</span></code></a>([memo])</p></td>
<td><p>Return a deep copy of this embedding.</p></td>
</tr>
</tbody>
</table>
</div>
<hr class="docutils" />
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_dict</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>ndarray</em><em>]</em>) – </p></li>
<li><p><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><em>...</em><em>]</em>) – </p></li>
<li><p><strong>normal_vec_name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – </p></li>
<li><p><strong>bias_name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – </p></li>
<li><p><strong>scaling_factor</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>ndarray</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__copy__">
<span class="sig-name descname"><span class="pre">__copy__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.__copy__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__copy__" title="Permalink to this definition"></a></dt>
<dd><p>Return a copy of this embedding.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__deepcopy__">
<span class="sig-name descname"><span class="pre">__deepcopy__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">memo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.__deepcopy__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__deepcopy__" title="Permalink to this definition"></a></dt>
<dd><p>Return a deep copy of this embedding.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__eq__">
<span class="sig-name descname"><span class="pre">__eq__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.__eq__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__eq__" title="Permalink to this definition"></a></dt>
<dd><p>Convert both embeddings to unique representation and compare values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>other</strong> (<a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__getattr__">
<span class="sig-name descname"><span class="pre">__getattr__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.__getattr__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__getattr__" title="Permalink to this definition"></a></dt>
<dd><p>Hand over attribute access to meta_infos if necessary.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normal_vec_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scaling_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">meta_info</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__init__" title="Permalink to this definition"></a></dt>
<dd><p>Init.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_dict</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Dict" title="(in Python v3.6)"><em>Dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>, </em><em>ndarray</em><em>]</em>) – numpy representations of a
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v1.11.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></a> state dict describing
the concept model of this embedding</p></li>
<li><p><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>, </em><em>...</em><em>]</em>) – see <a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.kernel_size" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.kernel_size"><code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></a></p></li>
<li><p><strong>normal_vec_name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – the key of the concept vector within
<code class="docutils literal notranslate"><span class="pre">state_dict</span></code></p></li>
<li><p><strong>bias_name</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Optional" title="(in Python v3.6)"><em>Optional</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a><em>]</em>) – the key of the bias within <code class="docutils literal notranslate"><span class="pre">state_dict</span></code></p></li>
<li><p><strong>support_factor</strong> – the negative concept threshold;
calculates as <code class="docutils literal notranslate"><span class="pre">-bias</span></code> over squared normal vec length</p></li>
<li><p><strong>scaling_factor</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><em>ndarray</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em>]</em>) – see <a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.scaling_factor" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.scaling_factor"><code class="xref py py-attr docutils literal notranslate"><span class="pre">scaling_factor</span></code></a></p></li>
<li><p><strong>concept</strong> – the concept that is embedded;</p></li>
<li><p><strong>model_stump</strong> – the model up to the layer of the embedding;
part of <a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.meta_info" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.meta_info"><code class="xref py py-attr docutils literal notranslate"><span class="pre">meta_info</span></code></a></p></li>
<li><p><strong>layer_id</strong> – if <code class="docutils literal notranslate"><span class="pre">model_stump</span></code> is not given, optional
specification of the <code class="docutils literal notranslate"><span class="pre">layer_id</span></code>;
part of <a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.meta_info" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.meta_info"><code class="xref py py-attr docutils literal notranslate"><span class="pre">meta_info</span></code></a></p></li>
<li><p><strong>concept_name</strong> – if <code class="docutils literal notranslate"><span class="pre">concept</span></code> is not given,
optional specification of the name;
part of <a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.meta_info" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.meta_info"><code class="xref py py-attr docutils literal notranslate"><span class="pre">meta_info</span></code></a></p></li>
<li><p><strong>meta_info</strong> – any other meta information</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__repr__">
<span class="sig-name descname"><span class="pre">__repr__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.__repr__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__repr__" title="Permalink to this definition"></a></dt>
<dd><p>Information about concept, model, layer, concept vector and thresh.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.distance">
<span class="sig-name descname"><span class="pre">distance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">point</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.distance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.distance" title="Permalink to this definition"></a></dt>
<dd><p>Calc the scaled distance of point from the embedding hyperplane.
The distance from a point pt is given by</p>
<div class="math notranslate nohighlight">
\[d(pt) =
\text{scaling_factor} \cdot \left((n \circ pt)
- b (n \circ n)\right)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>point</strong> (<em>ndarray</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.first">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">first</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.first"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.first" title="Permalink to this definition"></a></dt>
<dd><p>Select a copy of the first element of the list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>embeddings</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a><em>]</em><em>]</em><em>]</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.forget_scaling">
<span class="sig-name descname"><span class="pre">forget_scaling</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.forget_scaling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.forget_scaling" title="Permalink to this definition"></a></dt>
<dd><p>Return the embedding with the same normal vec and support but
scaling factor 1.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.load">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filepath</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.load" title="Permalink to this definition"></a></dt>
<dd><p>Load an embedding using <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.load.html#torch.load" title="(in PyTorch v1.11.0)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.load()</span></code></a>.
The format should be as used by <a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.save" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.save"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save()</span></code></a>.
For .npz files, a legacy loading mechanism based on
<code class="xref py py-func docutils literal notranslate"><span class="pre">numpy.load()</span></code> is used.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Be aware that unpickling is used for loading.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>filepath</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.mean">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.mean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.mean" title="Permalink to this definition"></a></dt>
<dd><p>Get the normalized embedding with distance fctn mean of the
normalized distance fctns.
Consider the non-scaled distance functions of the normalized versions
of the given embeddings. Then the condition for the normalized mean
embedding is that at any point the distance from the embedding
hyperplane to the point is the mean distance of these normalized
distances:</p>
<div class="math notranslate nohighlight">
\[d_{\frac{n}{|n|}, b\cdot |n|}
= mean\left( d_{\frac{n_j}{|n_j|}, |n_j|\cdot b_j} \right)\]</div>
<p>The scaling factor in the end is the mean of the scaling factors of
the normalized representations of the given embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>normalized</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/exceptions.html#ValueError" title="(in Python v3.6)"><code class="xref py py-exc docutils literal notranslate"><span class="pre">ValueError</span></code></a> if
<span class="math notranslate nohighlight">\(mean\left(\frac{n_j}{|n_j|}\right)\)</span> of the scaled
normal vectors <span class="math notranslate nohighlight">\(n_j\)</span> is 0</p>
</dd>
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>embeddings</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a><em>]</em><em>]</em><em>]</em>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.mean_by_angle">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">mean_by_angle</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.mean_by_angle"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.mean_by_angle" title="Permalink to this definition"></a></dt>
<dd><p>Get embedding where distance to the given hyperplanes at each
point sums up to 0.</p>
<p><strong>The Math Behind</strong></p>
<p>This routine approximates an “average” hyperplane from the given
embeddings where here average hyperplane means the one for which the
following holds:
Given a point <span class="math notranslate nohighlight">\(x\)</span> on the average hyperplane, the signed
distances to all hyperplanes along the average hyperplane’s normal
vector sum up to zero.
The signed distance from <span class="math notranslate nohighlight">\(x\)</span> to a hyperplane H non-orthogonal
to the average hyperplane is</p>
<div class="math notranslate nohighlight">
\[\left(\left( (R\cdot n + x) \cap H \right) - x \right) \circ n,\]</div>
<p>where</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n\)</span> is the normalized normal vector of the average hyperplane,</p></li>
<li><p><span class="math notranslate nohighlight">\((R \cdot n + x)\)</span> is the 1-dim affine sub-space through
<span class="math notranslate nohighlight">\(x\)</span> in the direction of <span class="math notranslate nohighlight">\(n\)</span>, and</p></li>
<li><p><span class="math notranslate nohighlight">\(((R \cdot n + x) \cap H)\)</span> is the unique intersection of
above line with <span class="math notranslate nohighlight">\(H\)</span>.</p></li>
</ul>
</div></blockquote>
<p>The average hyperplane has the following properties:</p>
<ul>
<li><p>The average hyperplane is unique.</p></li>
<li><p>The average normal vector only depends on the normal vectors of the
hyperplanes, not their supports/biases.</p></li>
<li><p>Given the normalized normal vector n of the average hyperplane,
a support vector is given by:</p>
<div class="math notranslate nohighlight">
\[\frac{1}{N} \sum_{j=1}^{N} \frac{|b_j|^2}{n \circ b_j} \cdot n\]</div>
<p>where the sum goes over the N hyperplanes, <span class="math notranslate nohighlight">\(n\)</span> is a normalized
normal vector of the average hyperplane and <span class="math notranslate nohighlight">\(b_j\)</span> is the
orthogonal support vector of the jth hyperplane
(i.e. a support vector which is a multiple of the normal vector).</p>
</li>
<li><p>Assume normalized normal vectors of the hyperplanes which all lie in
the same hypersphere and are given in angle coordinates of the
1-hypersphere. An entry in the average normal vector in angle
coordinates is the mean of the entries in the other hyperplane’s
normal vectors.</p></li>
</ul>
<p><strong>Implementation Notes</strong></p>
<dl class="simple">
<dt>Normal vector:</dt><dd><p>The normal vector is computationally expensive to calculate
(should be the spherical barycenter of the normed normal vectors
in one hemisphere)
and can be approximated by the normalized barycenter of the
normalized normal vectors which lie in the same hemisphere.</p>
</dd>
<dt>Support:</dt><dd><p>If the normal vectors do not differ too much, the support can also
be approximated by the mean of the orthogonal support vectors
(or be considered as an optimisation problem
and be learned from the concept data).</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>embeddings</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a><em>]</em><em>]</em><em>]</em>) – list of embeddings or list of list of embeddings</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The embedding representing the average hyperplane of the
hyperplanes represented by the given embeddings</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/exceptions.html#ValueError" title="(in Python v3.6)"><code class="xref py py-exc docutils literal notranslate"><span class="pre">ValueError</span></code></a> if the mean of the normalized normal
vectors <span class="math notranslate nohighlight">\(\frac{n_j}{|n_j|}\)</span> of the given embeddings is 0</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.mean_by_distance">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">mean_by_distance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.mean_by_distance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.mean_by_distance" title="Permalink to this definition"></a></dt>
<dd><p>Get embedding with distance measure being the mean of given embs.
This routine only works if the mean of the scaled embeddings normal
vectors is non-zero.</p>
<p>The distance of a point <span class="math notranslate nohighlight">\(x\)</span> from a hyperplane <span class="math notranslate nohighlight">\((n, b)\)</span>
with normal vector <span class="math notranslate nohighlight">\(n\)</span> and support vector <span class="math notranslate nohighlight">\(b\cdot n\)</span> is
defined as</p>
<div class="math notranslate nohighlight">
\[d_{n,b}(x)
= \left((x - b\cdot n) \circ n\right)
= x \circ n - b \cdot |n|^2\]</div>
<p>For an embedding <span class="math notranslate nohighlight">\((n, b, s)\)</span> with scaling factor s the distance
measure is the one of its scaled version <span class="math notranslate nohighlight">\((s n, \frac{b}{s}, 1)\)</span>,
which turns out to be</p>
<div class="math notranslate nohighlight">
\[d_{s n, \frac{b}{s}} = s \cdot d_{n,b}\]</div>
<p>This routine determines the “average” hyperplane for the given
embeddings, where here average hyperplane <span class="math notranslate nohighlight">\((n, b)\)</span> means the
one with the following property:</p>
<div class="math notranslate nohighlight">
\[d_{n,b}
= mean(d_{n_j,b_j})
= \frac 1 N \sum_{j=1}^{N} d_{n_j,b_j}\]</div>
<p>i.e. at any point <span class="math notranslate nohighlight">\(x\)</span> in space the distance of the average
hyperplane to <span class="math notranslate nohighlight">\(x\)</span> is the mean of the distances of all N given
hyperplanes <span class="math notranslate nohighlight">\((n_j,b_j)\)</span> to <span class="math notranslate nohighlight">\(x\)</span>. It is unique (the points
on the plane are those with distance 0 and thus all the same),
and given by the following combination (with scaling factor 1):</p>
<div class="math notranslate nohighlight">
\[\begin{split}n &amp;= mean(n_j) \\
b &amp;= \frac{1}{|n|^2} mean(b_j \cdot |n_j|^2)\end{split}\]</div>
<p>Possible problems: This will weight the contribution of the given
embeddings by their confidence, i.e. their scaling factor.
To avoid this, the mean can be taken over the normalized versions
with scaling factor set to one and the scaling factor of the mean can
be determined by confidence calibration.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>embedding describing the hyperplane with above properties</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p>ValueError if the mean of the scaled normal vectors of the
given embeddings is 0</p>
</dd>
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>embeddings</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a><em>]</em><em>]</em><em>]</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.normalize">
<span class="sig-name descname"><span class="pre">normalize</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.normalize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.normalize" title="Permalink to this definition"></a></dt>
<dd><p>Yield a new, equivalent embedding with normalized normal vec.
The sign of the scaling factor is not changed.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filepath</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.save" title="Permalink to this definition"></a></dt>
<dd><p>Save the embedding parameters and some description as torch pt file.
Load the embedding using <a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.load" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.load"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filepath</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – </p></li>
<li><p><strong>overwrite</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.scale">
<span class="sig-name descname"><span class="pre">scale</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.scale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.scale" title="Permalink to this definition"></a></dt>
<dd><p>Return a new equivalent embedding with <code class="docutils literal notranslate"><span class="pre">scaling_factor</span> <span class="pre">==</span> <span class="pre">1</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.std_deviation">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">std_deviation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ddof</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.std_deviation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.std_deviation" title="Permalink to this definition"></a></dt>
<dd><p>Get the (by default unbiased) standard deviation of a list of embs.
The standard deviations are calculated on the unique normalized
representations of the embeddings, and encompass standard deviation of:</p>
<ul class="simple">
<li><p>the normal vector</p></li>
<li><p>the support vector factor (= distance to 0)</p></li>
<li><p>the scaling factor (= length of the normal vector).</p></li>
</ul>
<p>The deviations are calculated as the square root of the variances
(see <a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.variance" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.variance"><code class="xref py py-meth docutils literal notranslate"><span class="pre">variance()</span></code></a>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embeddings</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a><em>]</em><em>]</em><em>]</em>) – sequence of embeddings</p></li>
<li><p><strong>ddof</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – delta degrees of freedom: the divisor used in calculations
is <span class="math notranslate nohighlight">\(\text{num_embeddings} - \text{ddof}\)</span>;
if <code class="docutils literal notranslate"><span class="pre">ddof=1</span></code> (default), the unbiased standard  deviation is
obtained</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple of standard deviation of
<code class="docutils literal notranslate"><span class="pre">(normal</span> <span class="pre">vecs,</span> <span class="pre">support</span> <span class="pre">factors,</span> <span class="pre">scaling</span> <span class="pre">factors)</span></code> for
normalized representations of given embeddings</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a>[<em>ndarray</em>, <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>, <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.to_pos_scaling">
<span class="sig-name descname"><span class="pre">to_pos_scaling</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.to_pos_scaling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.to_pos_scaling" title="Permalink to this definition"></a></dt>
<dd><p>Return the representation of this embedding with positive scaling.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.unique">
<span class="sig-name descname"><span class="pre">unique</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.unique"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.unique" title="Permalink to this definition"></a></dt>
<dd><p>Yield new, equivalent, unique embedding with normalized normal vec
and pos scaling.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.unique_upper_sphere">
<span class="sig-name descname"><span class="pre">unique_upper_sphere</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.unique_upper_sphere"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.unique_upper_sphere" title="Permalink to this definition"></a></dt>
<dd><p>Yield new equivalent, unique embedding with normal vec normalized
in upper hemisphere.</p>
<p>An embedding defines a hyperplane as follows:</p>
<ul class="simple">
<li><p>the <span class="math notranslate nohighlight">\(weight\)</span> is a (not necessarily normalized) normal vector
of the hyperplane</p></li>
<li><p><span class="math notranslate nohighlight">\(bias \cdot weight\)</span> is a support vector orthogonal to the plane</p></li>
</ul>
<p>This representation is not unique.
In many cases it is desirable to consider the representation where
the normal vector is normalized, and lies on the upper half of a
given sphere (including the equator). To also obtain unique results
for the equator cases, the rule is that, when flattened, the first
non-zero entry is positive.
The representation obtained then as follows is unique
(sign(weight) is the sign of the first non-zero entry when flattened):</p>
<div class="math notranslate nohighlight">
\[\begin{split}weight_{new} &amp;= sign(weight) \cdot \frac{weight} {|weight|} \\
bias_{new}   &amp;= sign(weight) \cdot (bias \cdot |weight|)\end{split}\]</div>
<p>Then the weight is normalized and</p>
<div class="math notranslate nohighlight">
\[weight_{new} \cdot bias_{new} = weight \cdot bias\]</div>
<p>is still an orthogonal support vector.
Two equivalent representations will yield the same such
normalized embedding.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Equivalent embedding where the weight of the output embedding
is normalized and, when flattened, the weight’s first non-zero
entry is positive</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/exceptions.html#ValueError" title="(in Python v3.6)"><code class="xref py py-exc docutils literal notranslate"><span class="pre">ValueError</span></code></a>, if the weight of the embedding is zero</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.variance">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">variance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embeddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ddof</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/hybrid_learning/concepts/models/embeddings.html#ConceptEmbedding.variance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.variance" title="Permalink to this definition"></a></dt>
<dd><p>Get the variance of a list of embeddings (by default unbiased).
The variances are calculated on the unique normalized representations
of the embeddings, and encompass variance of:</p>
<ul class="simple">
<li><p>the normal vector</p></li>
<li><p>the support vector factor (= distance to 0)</p></li>
<li><p>the scaling factor (= length of the normal vector).</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embeddings</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Union" title="(in Python v3.6)"><em>Union</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Sequence" title="(in Python v3.6)"><em>Sequence</em></a><em>[</em><a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding"><em>ConceptEmbedding</em></a><em>]</em><em>]</em><em>]</em>) – sequence of embeddings to take variance of</p></li>
<li><p><strong>ddof</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – delta degrees of freedom: the divisor used in calculations
is <span class="math notranslate nohighlight">\(\text{num_embeddings} - \text{ddof}\)</span>;
if <code class="docutils literal notranslate"><span class="pre">ddof=1</span></code> (default), the unbiased variance is obtained</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple of variance of
<code class="docutils literal notranslate"><span class="pre">(normal</span> <span class="pre">vecs,</span> <span class="pre">support</span> <span class="pre">factors,</span> <span class="pre">scaling</span> <span class="pre">factors)</span></code> for
normalized representations of given embeddings</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.6/library/typing.html#typing.Tuple" title="(in Python v3.6)"><em>Tuple</em></a>[<em>ndarray</em>, <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>, <a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__hash__">
<span class="sig-name descname"><span class="pre">__hash__</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.__hash__" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.bias">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">bias</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.bias" title="Permalink to this definition"></a></dt>
<dd><p>The bias <span class="math notranslate nohighlight">\(B\)</span> of the represented hyperplane.
A vector <span class="math notranslate nohighlight">\(v\)</span> is on the hyperplane defined by the normal vector
<span class="math notranslate nohighlight">\(n\)</span> and the bias <span class="math notranslate nohighlight">\(B\)</span> iff</p>
<div class="math notranslate nohighlight">
\[0 = d(v) = v \circ n + B\]</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.bias_name">
<span class="sig-name descname"><span class="pre">bias_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.bias_name" title="Permalink to this definition"></a></dt>
<dd><p>The key of the concept model bias within the state_dict.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.kernel_size">
<span class="sig-name descname"><span class="pre">kernel_size</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><span class="pre">int</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.kernel_size" title="Permalink to this definition"></a></dt>
<dd><p>The kernel size used by the concept model convolution.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.meta_info">
<span class="sig-name descname"><span class="pre">meta_info</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.meta_info" title="Permalink to this definition"></a></dt>
<dd><p>Any further meta information.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.normal_vec">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">normal_vec</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.normal_vec" title="Permalink to this definition"></a></dt>
<dd><p>A normal vector to the represented hyperplane.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.normal_vec_name">
<span class="sig-name descname"><span class="pre">normal_vec_name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.normal_vec_name" title="Permalink to this definition"></a></dt>
<dd><p>The key of the concept vector parameter within the state_dict.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.scaling_factor">
<span class="sig-name descname"><span class="pre">scaling_factor</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">numpy.ndarray</span></em><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.scaling_factor" title="Permalink to this definition"></a></dt>
<dd><p>The factor to obtain the original normal vector.
Only applies if a normal vector is given
(see <a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.normal_vec_name" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.normal_vec_name"><code class="xref py py-attr docutils literal notranslate"><span class="pre">normal_vec_name</span></code></a>).
Any two embeddings with normal vectors <span class="math notranslate nohighlight">\(n_1, n_2\)</span> and support
factors <span class="math notranslate nohighlight">\(b_1, b_2\)</span> fulfilling the following represent the same
hyperplane:</p>
<div class="math notranslate nohighlight">
\begin{align*}
\frac{|n_1 \circ n_2|} {(|n_1| \cdot |n_2|)} &amp;= 1 &amp;\text{and} &amp;&amp;
\frac{|n_1|} {|n_2|} &amp;= \frac{b_2} {b_1}
\end{align*}</div><p>However, the signed orthogonal distance measure of an embedding
<span class="math notranslate nohighlight">\((n, b)\)</span> for a vector <span class="math notranslate nohighlight">\(v\)</span></p>
<div class="math notranslate nohighlight">
\[d(v)
= (v - b \cdot n) \circ n
= |n| \cdot \left(v \circ \frac{n}{|n|}\right) - b\cdot|n|^2\]</div>
<p>which is used e.g. in concept layers, depends quadratic on the normal
vector length. If the hyperplane representation is changed,
the original normal vector and support factor
providing the original distance measure can be obtained via</p>
<div class="math notranslate nohighlight">
\[\left(n \cdot \text{scaling_factor} ,
\frac{b}{\text{scaling_factor}})\right.\]</div>
<p><em>Examples:</em>
The scaling_factor is 1 if the original weight was not changed,
and <span class="math notranslate nohighlight">\(|weight|\)</span> if it was normalized.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.settings">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">settings</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.settings" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary to reproduce the instance.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.state_dict" title="Permalink to this definition"></a></dt>
<dd><p>The concept model’s state dict. Assumed to be the result of a call to
:py:meth`torch.nn.Module.state_dict`.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.support_factor">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">support_factor</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.support_factor" title="Permalink to this definition"></a></dt>
<dd><p>A factor <span class="math notranslate nohighlight">\(b\)</span> to obtain the orthogonal support vector
<span class="math notranslate nohighlight">\(b\cdot n\)</span> from the normal vector <span class="math notranslate nohighlight">\(n\)</span>.
A vector <span class="math notranslate nohighlight">\(v\)</span> is on the hyperplane iff</p>
<div class="math notranslate nohighlight">
\[0 = d(v) = (v - b\cdot n) \circ n = v \circ n - b\cdot |n|^2\]</div>
<p>Here, <span class="math notranslate nohighlight">\(d(v)\)</span> denotes the signed orthogonal distance of <span class="math notranslate nohighlight">\(v\)</span>
from the hyperplane (cf. <a class="reference internal" href="#hybrid_learning.concepts.models.embeddings.ConceptEmbedding.bias" title="hybrid_learning.concepts.models.embeddings.ConceptEmbedding.bias"><code class="xref py py-attr docutils literal notranslate"><span class="pre">bias</span></code></a>).
If given, it is calculated from the bias <span class="math notranslate nohighlight">\(B\)</span> and the normal vector
<span class="math notranslate nohighlight">\(n\)</span> as <span class="math notranslate nohighlight">\(-\frac{B}{\|n\|^2}\)</span>.</p>
</dd></dl>

</dd></dl>

</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="hybrid_learning.concepts.models.embeddings.html" class="btn btn-neutral float-left" title="embeddings" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="hybrid_learning.concepts.models.model_extension.html" class="btn btn-neutral float-right" title="model_extension" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Continental Automotive GmbH.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>