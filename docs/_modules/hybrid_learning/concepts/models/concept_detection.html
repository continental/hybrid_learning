

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>hybrid_learning.concepts.models.concept_detection &mdash; hybrid_learning  documentation</title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/autoclasstoc.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home" alt="Documentation Home"> hybrid_learning
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Content</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../quickstart/index.html">Quickstart Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../userguide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../apiref/index.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../contributing.html">How to contribute</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">hybrid_learning</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
      <li>hybrid_learning.concepts.models.concept_detection</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for hybrid_learning.concepts.models.concept_detection</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Model for concept detection, and its training and evaluation handle.&quot;&quot;&quot;</span>
<span class="c1">#  Copyright (c) 2020 Continental Automotive GmbH</span>

<span class="kn">import</span> <span class="nn">hashlib</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Callable</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span>

<span class="kn">from</span> <span class="nn">.base_handles</span> <span class="kn">import</span> <span class="n">EarlyStoppingHandle</span><span class="p">,</span> <span class="n">ResettableOptimizer</span><span class="p">,</span> \
    <span class="n">TrainEvalHandle</span>
<span class="kn">from</span> <span class="nn">.model_extension</span> <span class="kn">import</span> <span class="n">ModelStump</span><span class="p">,</span> <span class="n">output_size</span>
<span class="kn">from</span> <span class="nn">..concepts</span> <span class="kn">import</span> <span class="n">SegmentationConcept2D</span><span class="p">,</span> <span class="n">ConceptTypes</span>
<span class="kn">from</span> <span class="nn">..embeddings</span> <span class="kn">import</span> <span class="n">ConceptEmbedding</span>
<span class="kn">from</span> <span class="nn">...datasets</span> <span class="kn">import</span> <span class="n">DatasetSplit</span><span class="p">,</span> <span class="n">BaseDataset</span><span class="p">,</span> <span class="n">ActivationDatasetWrapper</span><span class="p">,</span> \
    <span class="n">DataTriple</span>
<span class="kn">from</span> <span class="nn">...datasets.transforms</span> <span class="kn">import</span> <span class="n">SameSize</span><span class="p">,</span> <span class="n">same_padding</span><span class="p">,</span> <span class="n">TupleTransforms</span><span class="p">,</span> \
    <span class="n">Compose</span><span class="p">,</span> <span class="n">ToDevice</span><span class="p">,</span> <span class="n">OnBothSides</span>

<span class="n">LOGGER</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="ConceptDetectionModel2D"><a class="viewcode-back" href="../../../../apiref/generated/hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.html#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D">[docs]</a><span class="k">class</span> <span class="nc">ConceptDetectionModel2D</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pytorch model implementation of a concept embedding for 2D conv layers.</span>
<span class="sd">    The model itself simply is a convolutional layer with sigmoid activation.</span>
<span class="sd">    The goal of this model is to tell from an activation map, which spatial</span>
<span class="sd">    &quot;parts&quot; of the activation map belong to a given concept and which not.</span>
<span class="sd">    These parts are windows of the concept model :py:attr:`kernel_size`.</span>

<span class="sd">    The model features training and evaluation functionality for concept</span>
<span class="sd">    analysis, i.e. for training this concept module on the activation map output</span>
<span class="sd">    of the given model and layer without changing the main model.</span>

<span class="sd">    When the model forward works as follows:</span>

<span class="sd">    :Input: Activation map output of a 2D convolutional layer.</span>
<span class="sd">    :Output:</span>
<span class="sd">        Heatmap showing which centers of boxes of :py:attr:`kernel_size` belong</span>
<span class="sd">        to :py:attr:`concept`.</span>
<span class="sd">        The heatmap values are the sigmoid of a convolution operation.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">concept</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SegmentationConcept2D</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;The concept (data) for which this model is/should be trained.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_concept</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">concept_name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;The name of the associated concept if known.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_concept_name</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">concept</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">concept</span><span class="o">.</span><span class="n">name</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">main_model_stump</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelStump</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Stump of the main model in the head of which to localize the</span>
<span class="sd">        concept embedding.</span>
<span class="sd">        Used to generate the activation maps needed for concept analysis</span>
<span class="sd">        training. The actual attribute is wrapped into a tuple to hide the</span>
<span class="sd">        parameters, since these shall not be updated; see</span>
<span class="sd">        https://discuss.pytorch.org/t/how-to-exclude-parameters-from-model/6151</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_main_model_stump</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="nd">@main_model_stump</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">main_model_stump</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">main_model_stump</span><span class="p">:</span> <span class="n">ModelStump</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Setter of :py:attr:`main_model_stump`.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_main_model_stump</span> <span class="o">=</span> <span class="p">(</span><span class="n">main_model_stump</span><span class="p">,)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">main_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Shortcut to access the main model.</span>
<span class="sd">         It is wrapped by :py:attr:`main_model_stump`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">main_model_stump</span><span class="o">.</span><span class="n">wrapped_model</span> \
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">main_model_stump</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">layer_id</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Layer to extract concept from.</span>
<span class="sd">        Shortcut to access the information from :py:attr:`main_model_stump`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">main_model_stump</span><span class="o">.</span><span class="n">stump_head</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">kernel_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Size of the convolution kernel.</span>
<span class="sd">        This is the assumed concept size in activation map pixels.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">concept_layer</span><span class="o">.</span><span class="n">kernel_size</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">in_channels</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Number of input channels.</span>
<span class="sd">        This is the number of output channels of layer to investigate.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">concept_layer</span><span class="o">.</span><span class="n">in_channels</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">settings</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;The current model settings as dictionary.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">concept</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">concept</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">main_model</span><span class="p">,</span>
            <span class="n">layer_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_id</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span>
        <span class="p">)</span>

<div class="viewcode-block" id="ConceptDetectionModel2D.__init__"><a class="viewcode-back" href="../../../../apiref/generated/hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.html#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">concept</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SegmentationConcept2D</span><span class="p">],</span>
                 <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">],</span> <span class="n">layer_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
                 <span class="n">kernel_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">concept_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="c1"># pylint: disable=line-too-long</span>
        <span class="sd">&quot;&quot;&quot;Init.</span>

<span class="sd">        :param model: model the concept should be embedded in;</span>
<span class="sd">            used to create (and later accessible in)</span>
<span class="sd">            :py:attr:`main_model_stump`;</span>
<span class="sd">            used for :py:attr:`kernel_size` and :py:attr:`in_channels`</span>
<span class="sd">            auto-inference</span>
<span class="sd">        :param layer_id: the layer index in</span>
<span class="sd">            :py:meth:`~torch.nn.Module.state_dict`, the output of which is to</span>
<span class="sd">            be fed to the the concept model; used to create (and later</span>
<span class="sd">            accessible) in :py:attr:`main_model_stump`;</span>
<span class="sd">            used for :py:attr:`kernel_size` and :py:attr:`in_channels`</span>
<span class="sd">            auto-inference</span>
<span class="sd">        :param concept: Concept to train for; must be a segmentation concept</span>
<span class="sd">            featuring ground truth masks; used for :py:attr:`kernel_size` and</span>
<span class="sd">            :py:attr:`in_channels` auto-inference</span>
<span class="sd">        :param in_channels: Number of filters of the</span>
<span class="sd">            :py:class:`~torch.nn.Conv2d`-Layer to analyse;</span>
<span class="sd">            the value is automatically determined if ``in_channels`` or</span>
<span class="sd">            ``kernel_size`` is ``None``;</span>
<span class="sd">            an automatically generated value overwrites a given value with a</span>
<span class="sd">            warning</span>
<span class="sd">        :param kernel_size: Size in activation map pixels of a window for</span>
<span class="sd">            which to assess whether it is part of the ``concept`` or not;</span>
<span class="sd">            by default it is determined by the relative sizes in the concept&#39;s</span>
<span class="sd">            :py:attr:`~hybrid_learning.concepts.concepts.SegmentationConcept2D.rel_size`</span>
<span class="sd">            and the layer output size;</span>
<span class="sd">            if ``concept.rel_size`` is not set, :py:attr:`kernel_size` is set to</span>
<span class="sd">            ``(1, 1)`` with a warning</span>
<span class="sd">        :param concept_name: The default value for the :py:attr:`concept_name`</span>
<span class="sd">            property if :py:attr:`concept` is ``None``; serves as ID for</span>
<span class="sd">            the concept model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># pylint: enable=line-too-long</span>
        <span class="c1"># Parameter post-processing:</span>
        <span class="k">if</span> <span class="n">concept</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">concept</span><span class="p">:</span> <span class="n">SegmentationConcept2D</span> <span class="o">=</span> <span class="n">SegmentationConcept2D</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">concept</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">ConceptDetectionModel2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_main_model_stump</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">ModelStump</span><span class="p">]</span> <span class="o">=</span> \
            <span class="p">(</span><span class="n">ModelStump</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">layer_id</span><span class="p">),)</span> \
                <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span>
        <span class="sd">&quot;&quot;&quot;Stump of the main model in the head of which to localize the</span>
<span class="sd">        concept embedding. Used to generate the activation maps needed for</span>
<span class="sd">        concept analysis training.</span>
<span class="sd">        Must be wrapped into a tuple to hide the parameters from being added to</span>
<span class="sd">        the :py:meth:`torch.nn.Module.state_dict`, since these are not to be</span>
<span class="sd">        updated.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_concept</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SegmentationConcept2D</span><span class="p">]</span> <span class="o">=</span> <span class="n">concept</span>
        <span class="sd">&quot;&quot;&quot;Internal storage of the concept to localize.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_concept_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">_concept</span><span class="o">.</span><span class="n">name</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_concept</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">concept_name</span>
        <span class="sd">&quot;&quot;&quot;Default value for :py:attr:`concept_name` property</span>
<span class="sd">        if :py:attr:`concept` is ``None``.&quot;&quot;&quot;</span>

        <span class="c1"># automatically determine kernel_size and in_channels if one isn&#39;t given</span>
        <span class="c1"># (this may be time consuming as it requires one run through the model);</span>
        <span class="c1"># automatic determination is not possible if concept.rel_size is None,</span>
        <span class="c1"># in this case set the kernel_size to (1,1)</span>
        <span class="k">if</span> <span class="n">in_channels</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">kernel_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">concept</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Concept not given, so cannot auto-infer &quot;</span>
                                 <span class="s2">&quot;sizes, but in_channels or kernel_size not &quot;</span>
                                 <span class="s2">&quot;given.&quot;</span><span class="p">)</span>
            <span class="n">auto_in_channels</span><span class="p">,</span> <span class="n">auto_kernel_size</span> <span class="o">=</span> \
                <span class="bp">self</span><span class="o">.</span><span class="n">_layer_out_info</span><span class="p">(</span><span class="n">concept</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">main_model_stump</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">in_channels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">in_channels</span> <span class="o">!=</span> <span class="n">auto_in_channels</span><span class="p">:</span>
                <span class="n">LOGGER</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;The number of in_channels specified for </span><span class="si">%s</span><span class="s2"> was </span><span class="si">%d</span><span class="s2">, but the&quot;</span>
                    <span class="s2">&quot; automatically determined value was </span><span class="si">%d</span><span class="s2">; taking auto one&quot;</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">auto_in_channels</span><span class="p">)</span>
            <span class="n">in_channels</span> <span class="o">=</span> <span class="n">auto_in_channels</span>
            <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span> \
                <span class="k">if</span> <span class="n">kernel_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">auto_kernel_size</span>

        <span class="c1"># Layers</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> \
            <span class="s2">&quot;kernel size not of len 2: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span>
        <span class="c1"># Beware: The padding for ZeroPad2d has crude specification:</span>
        <span class="c1"># 1. width pad, 2. height pad</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ZeroPad2d</span><span class="p">(</span>
            <span class="n">padding</span><span class="o">=</span><span class="n">same_padding</span><span class="p">((</span><span class="n">kernel_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">kernel_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">concept_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
                                             <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
                                             <span class="n">out_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="sd">&quot;&quot;&quot;The Conv layer which is trained to detect windows</span>
<span class="sd">        in which concept is located.</span>
<span class="sd">        The number of input channels is automatically determined if not given</span>
<span class="sd">        as ``in_channels`` in the ``__init__`` call.</span>
<span class="sd">        (automatic determination requires one forward of the main model).&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="sd">&quot;&quot;&quot;The sigmoid activation layer to obtain heatmaps in ``[0,1]``.&quot;&quot;&quot;</span></div>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_layer_out_info</span><span class="p">(</span><span class="n">concept</span><span class="p">:</span> <span class="n">SegmentationConcept2D</span><span class="p">,</span>
                        <span class="n">main_model_stump</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span>
                        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]:</span>
        <span class="c1"># pylint: disable=line-too-long</span>
        <span class="sd">&quot;&quot;&quot;Extract channel and kernel size information from model output.</span>
<span class="sd">        This is done by collecting the layer output size from one forward run</span>
<span class="sd">        of the model.</span>
<span class="sd">        It is then assumed that the layer output is a tensor of shape</span>
<span class="sd">        ``(output channels/filters, height, width, ...)``, where</span>
<span class="sd">        ``height, width, ...`` is activation map shape information that</span>
<span class="sd">        should have the same number of dimensions as the</span>
<span class="sd">        :py:attr:`~hybrid_learning.concepts.concepts.SegmentationConcept2D.rel_size` of</span>
<span class="sd">        the ``concept``, if this is set.</span>

<span class="sd">        :param main_model_stump: the model of which to analyse the output;</span>
<span class="sd">            output must be a single tensor with size of shape</span>
<span class="sd">            ``(output channels/filters, width, height, ...)``</span>
<span class="sd">        :param concept: the concept from which to draw the dummy sample size</span>
<span class="sd">            and the concept size</span>
<span class="sd">        :return: tuple of</span>
<span class="sd">            :in_channels: number of output channels of the layer) and of</span>
<span class="sd">            :kernel_size:</span>
<span class="sd">                the size in activation map pixels the kernel must have to</span>
<span class="sd">                provide (up to rounding) the same aspect ratio as specified</span>
<span class="sd">                in the :py:attr:`~hybrid_learning.concepts.concepts.SegmentationConcept2D.rel_size`</span>
<span class="sd">                of the ``concept`` if this is set;</span>
<span class="sd">                if ``concept.rel_size`` is not set, ``kernel_size`` is ``(1,1)``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># pylint: enable=line-too-long</span>
        <span class="n">inp</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">concept</span><span class="o">.</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># layer output size without batch dimension:</span>
        <span class="n">layer_out_size</span> <span class="o">=</span> <span class="n">output_size</span><span class="p">(</span><span class="n">main_model_stump</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

        <span class="c1"># Some size checks:</span>
        <span class="c1"># assuming layer_out_size = batch + (filters, width, height)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_out_size</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                <span class="p">(</span><span class="s2">&quot;The size of layer </span><span class="si">{}</span><span class="s2"> output was not of shape &quot;</span>
                 <span class="s2">&quot;(filters, width, height), but was </span><span class="si">{}</span><span class="s2">&quot;</span>
                 <span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">main_model_stump</span><span class="o">.</span><span class="n">stump_head</span><span class="p">,</span> <span class="n">layer_out_size</span><span class="p">))</span>
        <span class="c1"># assuming layer_out_size[1:] gives same image dimensions as</span>
        <span class="c1"># concept.rel_size</span>
        <span class="k">if</span> <span class="n">concept</span><span class="o">.</span><span class="n">rel_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">concept</span><span class="o">.</span><span class="n">rel_size</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span>
                <span class="n">layer_out_size</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                <span class="p">(</span><span class="s2">&quot;The concept size has </span><span class="si">{}</span><span class="s2"> image dimensions, the layer &quot;</span>
                 <span class="s2">&quot;output has </span><span class="si">{}</span><span class="s2">; concept size: </span><span class="si">{}</span><span class="s2">, layer out size: </span><span class="si">{}</span><span class="s2">&quot;</span>
                 <span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">concept</span><span class="o">.</span><span class="n">rel_size</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_out_size</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                          <span class="n">concept</span><span class="o">.</span><span class="n">rel_size</span><span class="p">,</span> <span class="n">layer_out_size</span><span class="p">))</span>

        <span class="c1"># in_channels is by default the number of output filters of the layer:</span>
        <span class="n">auto_in_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">layer_out_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># kernel_size is by default the percentage of the layer output size</span>
        <span class="c1"># given by concept size;</span>
        <span class="c1"># if concept.rel_size is not set, it is (1,1)</span>
        <span class="k">if</span> <span class="n">concept</span><span class="o">.</span><span class="n">rel_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">([</span><span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">s</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">concept</span><span class="o">.</span><span class="n">rel_size</span><span class="p">]):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">((</span><span class="s2">&quot;Some concept size entries are invalid (not &quot;</span>
                                  <span class="s2">&quot;in [0,1]): </span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">concept</span><span class="o">.</span><span class="n">rel_size</span><span class="p">))</span>
            <span class="n">auto_kernel_size</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">r</span> <span class="o">*</span> <span class="n">o</span><span class="p">)))</span>
                                      <span class="k">for</span> <span class="n">r</span><span class="p">,</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">concept</span><span class="o">.</span><span class="n">rel_size</span><span class="p">,</span>
                                                      <span class="n">layer_out_size</span><span class="p">[</span><span class="mi">1</span><span class="p">:])])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">LOGGER</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;concept.rel_size is not set; setting &quot;</span>
                           <span class="s2">&quot;auto_kernel_size to (1, 1)&quot;</span><span class="p">)</span>
            <span class="n">auto_kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">auto_in_channels</span><span class="p">,</span> <span class="n">auto_kernel_size</span>

<div class="viewcode-block" id="ConceptDetectionModel2D.reset_parameters"><a class="viewcode-back" href="../../../../apiref/generated/hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.html#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.reset_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Randomly (re)initialize weight and bias.&quot;&quot;&quot;</span>

        <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
        <span class="k">def</span> <span class="nf">reset_params</span><span class="p">(</span><span class="n">module</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
            <span class="sd">&quot;&quot;&quot;Try to call a parameter reset method within module.&quot;&quot;&quot;</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;reset_parameters&#39;</span><span class="p">):</span>
                <span class="c1"># noinspection PyCallingNonCallable</span>
                <span class="n">module</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">child</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
            <span class="n">reset_params</span><span class="p">(</span><span class="n">child</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConceptDetectionModel2D.to_embedding"><a class="viewcode-back" href="../../../../apiref/generated/hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.html#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.to_embedding">[docs]</a>    <span class="k">def</span> <span class="nf">to_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ConceptEmbedding</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return the plain representation as</span>
<span class="sd">        :py:class:`~hybrid_learning.concepts.embeddings.ConceptEmbedding`.</span>
<span class="sd">        I.e.</span>

<span class="sd">        :as parameters: weight and bias of :py:attr:`concept_layer`, and</span>
<span class="sd">        :as meta info:</span>
<span class="sd">            the :py:attr:`concept` and :py:attr:`main_model`</span>
<span class="sd">            with :py:attr:`layer_id`.</span>

<span class="sd">        .. note::</span>
<span class="sd">            This must be a deep copy to avoid overwriting in a consecutive</span>
<span class="sd">            training session.</span>

<span class="sd">        The resulting embedding describes the decision hyperplane of the</span>
<span class="sd">        concept model. Its normal vector :math:`n` is the concept layer weight.</span>
<span class="sd">        The orthogonal support vector given by :math:`b\cdot n` for a scalar</span>
<span class="sd">        factor :math:`b` must fulfill</span>

<span class="sd">        .. math::</span>
<span class="sd">            \forall v: (v - b\cdot n) \circ n</span>
<span class="sd">            = d(v)</span>
<span class="sd">            = (v \circ \text{weight}) + \text{bias}</span>

<span class="sd">        i.e.</span>

<span class="sd">        .. math::</span>
<span class="sd">            n = \text{weight} \quad\text{and}\quad</span>
<span class="sd">            b = - \frac{\text{bias}} {|\text{weight}|^2}.</span>

<span class="sd">        Here, :math:`d(v)` is the signed distance measure of a vector</span>
<span class="sd">        from the hyperplane, i.e.</span>

<span class="sd">        .. math::</span>
<span class="sd">            d(v)</span>
<span class="sd">            \begin{cases}</span>
<span class="sd">                &gt; 0  &amp; \text{iff vector yields a positive prediction,}\\</span>
<span class="sd">                \equiv 0 &amp; \text{iff vector on decision boundary hyperplane,}\\</span>
<span class="sd">                &lt; 0  &amp; \text{iff vector yields a negative prediction.}</span>
<span class="sd">            \end{cases}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">normal_vec</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">concept_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="n">normal_vec_length</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">normal_vec</span><span class="p">)</span>
        <span class="n">bias</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">concept_layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="n">support_factor</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="o">-</span> <span class="n">bias</span> <span class="o">/</span> <span class="p">(</span><span class="n">normal_vec_length</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ConceptEmbedding</span><span class="p">(</span><span class="n">normal_vec</span><span class="o">=</span><span class="n">normal_vec</span><span class="p">,</span>
                                <span class="n">support_factor</span><span class="o">=</span><span class="n">support_factor</span><span class="p">,</span>
                                <span class="n">concept</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">concept</span><span class="p">,</span>
                                <span class="n">model_stump</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">main_model_stump</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConceptDetectionModel2D.from_embedding"><a class="viewcode-back" href="../../../../apiref/generated/hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.html#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.from_embedding">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">from_embedding</span><span class="p">(</span><span class="n">embedding</span><span class="p">:</span> <span class="n">ConceptEmbedding</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span>
                       <span class="n">main_model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                       <span class="n">concept</span><span class="p">:</span> <span class="n">SegmentationConcept2D</span> <span class="o">=</span> <span class="kc">None</span>
                       <span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;ConceptDetectionModel2D&#39;</span><span class="p">:</span>
        <span class="c1"># pylint: disable=line-too-long</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Initialize a concept localization model from an embedding.</span>
<span class="sd">        The weight and bias are obtained as follows:</span>

<span class="sd">        :weight: The weight is the normal vector of the embedding</span>
<span class="sd">        :bias:</span>
<span class="sd">            Given the ``embedding``&#39;s</span>
<span class="sd">            :py:attr:`~hybrid_learning.concepts.embeddings.ConceptEmbedding.support_factor`</span>
<span class="sd">            as :math:`b`, the bias calculates as</span>
<span class="sd">            (compare :py:meth:`to_embedding`):</span>

<span class="sd">            .. math:: \text{bias} = - b \cdot (|\text{weight}|^2)</span>

<span class="sd">        :param embedding: the embedding to use</span>
<span class="sd">        :param main_model: ``main_model`` to use for init of the new</span>
<span class="sd">            :py:class:`ConceptDetectionModel2D`; defaults to the ``embedding``&#39;s</span>
<span class="sd">            :py:attr:`~hybrid_learning.concepts.embeddings.ConceptEmbedding.main_model`</span>
<span class="sd">        :param concept: ``concept`` to use for init of the new</span>
<span class="sd">            :py:class:`ConceptDetectionModel2D`</span>
<span class="sd">            must be valid input to the</span>
<span class="sd">            :py:meth:`~hybrid_learning.concepts.concepts.Concept.new` method</span>
<span class="sd">            of the</span>
<span class="sd">            :py:meth:`~hybrid_learning.concepts.concepts.SegmentationConcept2D`</span>
<span class="sd">            class; defaults to the ``embedding``&#39;s</span>
<span class="sd">            :py:attr:`~hybrid_learning.concepts.embeddings.ConceptEmbedding.concept`</span>
<span class="sd">        :return: a concept localization model initialized with the embedding</span>
<span class="sd">            information</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># pylint: enable=line-too-long</span>
        <span class="c1"># Value checks and defaults</span>
        <span class="n">concept</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SegmentationConcept2D</span><span class="p">]</span> <span class="o">=</span> <span class="n">concept</span> <span class="ow">or</span> <span class="n">embedding</span><span class="o">.</span><span class="n">concept</span>
        <span class="k">if</span> <span class="n">concept</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">concept</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="n">ConceptTypes</span><span class="o">.</span><span class="n">SEGMENTATION</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Expected embedded concept to be of type segmentation, &quot;</span>
                <span class="s2">&quot;but was </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">embedding</span><span class="o">.</span><span class="n">concept</span><span class="o">.</span><span class="n">type</span><span class="p">))</span>
        <span class="n">main_model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">main_model</span> <span class="ow">or</span> <span class="n">embedding</span><span class="o">.</span><span class="n">main_model</span>

        <span class="c1"># Apply the scaling factor</span>
        <span class="n">scaled_embedding</span> <span class="o">=</span> <span class="n">embedding</span><span class="o">.</span><span class="n">scale</span><span class="p">()</span>
        <span class="c1"># State dict collection (make sure the parameters are proper copies)</span>
        <span class="n">weight_np</span> <span class="o">=</span> <span class="n">scaled_embedding</span><span class="o">.</span><span class="n">normal_vec</span>
        <span class="n">bias_np</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">scaled_embedding</span><span class="o">.</span><span class="n">support_factor</span> <span class="o">*</span>
                    <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">scaled_embedding</span><span class="o">.</span><span class="n">normal_vec</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
        <span class="c1"># pylint: disable=not-callable</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;concept_layer.weight&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">weight_np</span><span class="p">),</span>
                      <span class="s1">&#39;concept_layer.bias&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">bias_np</span><span class="p">)}</span>
        <span class="c1"># pylint: enable=not-callable</span>

        <span class="c1"># Model init</span>
        <span class="n">c_model</span> <span class="o">=</span> <span class="n">ConceptDetectionModel2D</span><span class="p">(</span>
            <span class="n">concept</span><span class="o">=</span><span class="n">concept</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">main_model</span><span class="p">,</span>
            <span class="n">layer_id</span><span class="o">=</span><span class="n">scaled_embedding</span><span class="o">.</span><span class="n">layer_id</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">weight_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]),</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="n">scaled_embedding</span><span class="o">.</span><span class="n">normal_vec</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">concept_name</span><span class="o">=</span><span class="n">scaled_embedding</span><span class="o">.</span><span class="n">concept_name</span><span class="p">)</span>
        <span class="n">c_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">c_model</span></div>

<div class="viewcode-block" id="ConceptDetectionModel2D.forward"><a class="viewcode-back" href="../../../../apiref/generated/hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.html#hybrid_learning.concepts.models.concept_detection.ConceptDetectionModel2D.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">inp</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot;Torch model forward evaluation method.&quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> \
            <span class="s2">&quot;Only accepting one input tensor, but </span><span class="si">{}</span><span class="s2"> given&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="p">))</span>
        <span class="n">outp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">(</span><span class="o">*</span><span class="n">inp</span><span class="p">)</span>
        <span class="n">outp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">concept_layer</span><span class="p">(</span><span class="n">outp</span><span class="p">)</span>
        <span class="n">outp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">outp</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">outp</span></div></div>


<div class="viewcode-block" id="ConceptDetection2DTrainTestHandle"><a class="viewcode-back" href="../../../../apiref/generated/hybrid_learning.concepts.models.concept_detection.ConceptDetection2DTrainTestHandle.html#hybrid_learning.concepts.models.concept_detection.ConceptDetection2DTrainTestHandle">[docs]</a><span class="k">class</span> <span class="nc">ConceptDetection2DTrainTestHandle</span><span class="p">(</span><span class="n">TrainEvalHandle</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Train test handle for concept localization models.</span>
<span class="sd">    Takes the concept data of the concept model&#39;s concept, and automatically</span>
<span class="sd">    converts it appropriately for the concept model (see</span>
<span class="sd">    :py:meth:`data_from_concept`).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">DEFAULT_MASK_INTERPOLATION</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;bilinear&quot;</span>
    <span class="sd">&quot;&quot;&quot;Interpolation method used in default transforms for resizing masks</span>
<span class="sd">    to activation map size. Argument may be one of the modes accepted by</span>
<span class="sd">    :py:func:`torch.nn.functional.interpolate`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ConceptDetection2DTrainTestHandle.__init__"><a class="viewcode-back" href="../../../../apiref/generated/hybrid_learning.concepts.models.concept_detection.ConceptDetection2DTrainTestHandle.html#hybrid_learning.concepts.models.concept_detection.ConceptDetection2DTrainTestHandle.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">concept_model</span><span class="p">:</span> <span class="n">ConceptDetectionModel2D</span><span class="p">,</span>
                 <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">),</span>
                 <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
                 <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                 <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span>
                     <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">metric_fns</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[</span>
                     <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">early_stopping_handle</span><span class="p">:</span> <span class="n">EarlyStoppingHandle</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">optim_handle</span><span class="p">:</span> <span class="n">ResettableOptimizer</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">act_map_filepath_fns</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span>
                     <span class="n">DatasetSplit</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="n">BaseDataset</span><span class="p">],</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">transforms</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
                                      <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">model_output_transform</span><span class="p">:</span> <span class="n">TupleTransforms</span> <span class="o">=</span> <span class="kc">None</span>
                 <span class="p">):</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
        <span class="c1"># pylint: disable=line-too-long</span>
        <span class="sd">&quot;&quot;&quot;Init.</span>

<span class="sd">        For further parameter descriptions see ``__init__()`` of</span>
<span class="sd">        :py:class:`~hybrid_learning.concepts.models.base_handles.train_test_handle.TrainEvalHandle`.</span>

<span class="sd">        :param concept_model: the concept localization model to work on with</span>
<span class="sd">            concept.</span>
<span class="sd">        :param act_map_filepath_fns: dictionary of ``{split: func}`` where</span>
<span class="sd">            func is the functions for returning the path to an activation map</span>
<span class="sd">            file given index ``i`` and the base dataset behind ``split``.</span>
<span class="sd">            For details (e.g. on the default) see</span>
<span class="sd">            :py:meth:`hybrid_learning.datasets.activations_handle.ActivationDatasetWrapper.act_map_filepath_fn`.</span>
<span class="sd">        :param transforms: transformation the activation dataset wrapper should</span>
<span class="sd">            apply to the tuples of activation map and target mask tensors;</span>
<span class="sd">            must at least ensure that the output target mask tensor has the</span>
<span class="sd">            same shape as the output activation map tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># pylint: enable=line-too-long</span>
        <span class="c1"># Default transforms:</span>
        <span class="k">if</span> <span class="n">model_output_transform</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">transforms</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_output_transform</span> <span class="o">=</span> <span class="n">SameSize</span><span class="p">(</span>
                <span class="n">resize_target</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># resize the model output to image size!</span>
                <span class="n">interpolation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">DEFAULT_MASK_INTERPOLATION</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">transforms</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">transforms_wt_device</span><span class="p">:</span> <span class="n">Compose</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">([</span>
                <span class="n">OnBothSides</span><span class="p">(</span><span class="n">ToDevice</span><span class="p">(</span><span class="n">device</span><span class="p">)),</span> <span class="n">transforms</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">transforms_wt_device</span><span class="p">:</span> <span class="n">OnBothSides</span> <span class="o">=</span> \
                <span class="n">OnBothSides</span><span class="p">(</span><span class="n">ToDevice</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

        <span class="c1"># obtain train and test data</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">DataTriple</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_from_concept</span><span class="p">(</span>
            <span class="n">concept_model</span><span class="p">,</span> <span class="n">transforms_wt_device</span><span class="p">,</span> <span class="n">act_map_filepath_fns</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConceptDetection2DTrainTestHandle</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">concept_model</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">,</span>
            <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
            <span class="n">early_stopping_handle</span><span class="o">=</span><span class="n">early_stopping_handle</span><span class="p">,</span>
            <span class="n">metric_fns</span><span class="o">=</span><span class="n">metric_fns</span><span class="p">,</span>
            <span class="n">optimizer</span><span class="o">=</span><span class="n">optim_handle</span><span class="p">,</span>
            <span class="n">model_output_transform</span><span class="o">=</span><span class="n">model_output_transform</span>
        <span class="p">)</span>
        <span class="n">concept_model</span><span class="o">.</span><span class="n">main_model_stump</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># Trick to teach IDE the type of self.model:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">:</span> <span class="n">ConceptDetectionModel2D</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span></div>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_model_hash</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">truncate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a hex md5-hash of the main model topology for comparison</span>
<span class="sd">        purposes.</span>
<span class="sd">        Truncate to the first truncate letters if ``truncate`` is given.&quot;&quot;&quot;</span>
        <span class="n">hex_md5</span> <span class="o">=</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">md5</span><span class="p">(</span><span class="nb">repr</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">())</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">truncate</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">truncate</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;truncate value must be &gt; 0, but was </span><span class="si">{}</span><span class="s2">&quot;</span>
                                 <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">truncate</span><span class="p">))</span>
            <span class="n">hex_md5</span> <span class="o">=</span> <span class="n">hex_md5</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">truncate</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">hex_md5</span>

<div class="viewcode-block" id="ConceptDetection2DTrainTestHandle.data_from_concept"><a class="viewcode-back" href="../../../../apiref/generated/hybrid_learning.concepts.models.concept_detection.ConceptDetection2DTrainTestHandle.html#hybrid_learning.concepts.models.concept_detection.ConceptDetection2DTrainTestHandle.data_from_concept">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">data_from_concept</span><span class="p">(</span>
            <span class="bp">cls</span><span class="p">,</span>
            <span class="n">concept_model</span><span class="p">:</span> <span class="n">ConceptDetectionModel2D</span><span class="p">,</span>
            <span class="n">transforms</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
                                          <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]],</span>
            <span class="n">act_map_filepath_fns</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">DatasetSplit</span><span class="p">,</span>
                                       <span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="n">BaseDataset</span><span class="p">],</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataTriple</span><span class="p">:</span>
        <span class="c1"># pylint: disable=line-too-long</span>
        <span class="sd">&quot;&quot;&quot;Data handles with activation maps for and ground truth from</span>
<span class="sd">        :py:attr:`~ConceptDetectionModel2D.concept`.</span>
<span class="sd">        The data from the concept model&#39;s concept is wrapped by an</span>
<span class="sd">        :py:class:`~hybrid_learning.datasets.activations_handle.ActivationDatasetWrapper`.</span>
<span class="sd">        Its input and ground truth are:</span>

<span class="sd">        :input: the required activation maps of the main model</span>
<span class="sd">        :ground truth:</span>
<span class="sd">          the segmentation masks scaled to the activation map size</span>
<span class="sd">          (currently scaling is done on ``__getitem__``-call of</span>
<span class="sd">          :py:class:`~hybrid_learning.datasets.activations_handle.ActivationDatasetWrapper`)</span>

<span class="sd">        :raises: :py:exc:`ValueError` if the data dimensions do not fit the</span>
<span class="sd">            :py:attr:`~ConceptDetectionModel2D.in_channels` of the concept</span>
<span class="sd">            model&#39;s :py:attr:`~ConceptDetectionModel2D.concept_layer`.</span>
<span class="sd">        :return: tuple of train data, test data, validation data, all with</span>
<span class="sd">            activation maps as outputs</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># pylint: enable=line-too-long</span>
        <span class="n">main_model_stump</span><span class="p">:</span> <span class="n">ModelStump</span> <span class="o">=</span> <span class="n">concept_model</span><span class="o">.</span><span class="n">main_model_stump</span>
        <span class="n">common_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">act_map_gen</span><span class="o">=</span><span class="n">main_model_stump</span><span class="p">,</span>
            <span class="n">transforms</span><span class="o">=</span><span class="n">transforms</span><span class="p">,</span>
            <span class="n">model_description</span><span class="o">=</span><span class="p">(</span><span class="n">main_model_stump</span><span class="o">.</span><span class="n">wrapped_model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
                               <span class="o">+</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_model_hash</span><span class="p">(</span><span class="n">main_model_stump</span><span class="p">)))</span>

        <span class="n">splits</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">DatasetSplit</span><span class="p">,</span> <span class="n">ActivationDatasetWrapper</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">(</span><span class="n">DatasetSplit</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="n">DatasetSplit</span><span class="o">.</span><span class="n">TEST</span><span class="p">,</span> <span class="n">DatasetSplit</span><span class="o">.</span><span class="n">VAL</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">concept_model</span><span class="o">.</span><span class="n">concept</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">split</span><span class="p">]</span>

            <span class="c1"># Get the dataset_root</span>
            <span class="c1"># TODO: better handling of subsets and concatenations of datasets</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s2">&quot;dataset_root&quot;</span><span class="p">):</span>  <span class="c1"># is a BaseDataset like</span>
                <span class="n">dataset_root</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dataset_root</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s2">&quot;dataset&quot;</span><span class="p">):</span>  <span class="c1"># is a wrapper</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="s2">&quot;dataset_root&quot;</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                        <span class="p">(</span><span class="s2">&quot;Either data split </span><span class="si">{}</span><span class="s2"> (type </span><span class="si">{}</span><span class="s2">) or its attribute &quot;</span>
                         <span class="s2">&quot;dataset (type </span><span class="si">{}</span><span class="s2">) must provide a dataset_root &quot;</span>
                         <span class="s2">&quot;attribute.&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">split</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">),</span>
                                              <span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="p">)))</span>
                <span class="n">dataset_root</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">dataset_root</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                    <span class="p">(</span><span class="s2">&quot;Data split </span><span class="si">{}</span><span class="s2"> (type </span><span class="si">{}</span><span class="s2">) must provide a dataset_root &quot;</span>
                     <span class="s2">&quot;attribute or an attribute dataset that does so.&quot;</span>
                     <span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">split</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span>

            <span class="c1"># Get the activation map filepath function</span>
            <span class="n">act_map_filepath_fn</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">act_map_filepath_fns</span> <span class="k">else</span> \
                <span class="n">act_map_filepath_fns</span><span class="p">[</span><span class="n">split</span><span class="p">]</span>

            <span class="c1"># Create wrapper</span>
            <span class="n">splits</span><span class="p">[</span><span class="n">split</span><span class="p">]</span> <span class="o">=</span> <span class="n">ActivationDatasetWrapper</span><span class="p">(</span>
                <span class="n">dataset</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span>
                <span class="n">dataset_root</span><span class="o">=</span><span class="n">dataset_root</span><span class="p">,</span>
                <span class="n">act_map_filepath_fn</span><span class="o">=</span><span class="n">act_map_filepath_fn</span><span class="p">,</span>
                <span class="o">**</span><span class="n">common_args</span><span class="p">)</span>

        <span class="c1"># Validation: size checks</span>
        <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">concept_model</span><span class="o">.</span><span class="n">concept_layer</span><span class="o">.</span><span class="n">in_channels</span>
        <span class="k">for</span> <span class="n">split</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">splits</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">act_map</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">act_map</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">in_channels</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="p">(</span><span class="s2">&quot;in_channels (</span><span class="si">{}</span><span class="s2">) of concept layer does not match number &quot;</span>
                     <span class="s2">&quot;of filters in activation map of </span><span class="si">{}</span><span class="s2"> data sample 0 which &quot;</span>
                     <span class="s2">&quot;has size </span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">split</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
                                           <span class="n">act_map</span><span class="o">.</span><span class="n">size</span><span class="p">()))</span>

        <span class="k">return</span> <span class="n">DataTriple</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">splits</span><span class="p">)</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Continental Automotive GmbH

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>